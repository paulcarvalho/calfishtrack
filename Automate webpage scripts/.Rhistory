'  colnames(WR.surv1) <- c("Release Group", "Survival (%)", "SE", "95% lower C.I.", "95% upper C.I.", "Detection efficiency (%)")',
paste0('  print(kable(WR.surv1, row.names = F, "html", caption = "3.', table_count, ' Minimum survival to Benicia Bridge East Span (using CJS survival model)") %>%'),
'          kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
'',
'} else if(length(table(detects_benicia$general_location)) == 1){',
'  if(as.numeric(difftime(Sys.time(), min(detects_study$RelDT), units = "days"))>30){',
'    WR.surv <- data.frame("Release"="ALL", "estimate"=round(length(unique(detects_benicia$TagCode))/length(unique(detects_study$TagCode))*100,1),',
'                          "se"=NA, "lcl"=NA, "ucl"=NA, "Detection_efficiency"=NA)',
'',
'  } else {',
'    WR.surv <- data.frame("Release" = NA, "estimate" = "NOT ENOUGH DETECTIONS", "se" = NA, "lcl" = NA, "ucl" = NA, "Detection_efficiency" = NA)',
'  }',
'',
'  WR.surv1 <- WR.surv',
'  colnames(WR.surv1) <- c("Release Group", "Survival (%)", "SE", "95% lower C.I.", "95% upper C.I.", "Detection efficiency (%)")',
paste0('  print(kable(WR.surv1, row.names = F, "html", caption = "3.', table_count, ' Minimum survival to Benicia Bridge East Span (using CJS survival model)") %>%'),
'         kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
'',
'} else {',
'  # Only do survival to Benicia here',
'  test3 <- detects_study[which(detects_study$river_km < 53),]',
'',
'  # Create inp for survival estimation',
'  inp <- as.data.frame(reshape2::dcast(test3, TagCode ~ river_km, fun.aggregate = length))',
'',
'  # Sort columns by river km in descending order',
'  # Count number of genlocs',
'  gen_loc_sites <- ncol(inp)-1',
'',
'  inp  <- inp[,c(1,order(names(inp[,2:(gen_loc_sites+1)]), decreasing = T)+1)]',
'  inp  <- merge(study_tagcodes, inp, by = "TagCode", all.x = T)',
'  inp2 <- inp[,(ncol(inp)-gen_loc_sites+1):ncol(inp)]',
'',
'  inp2[is.na(inp2)] <- 0',
'  inp2[inp2 > 0]    <- 1',
'',
'  inp    <- cbind(inp, inp2)',
'  groups <- as.character(sort(unique(inp$Release)))',
'  groups_w_detects <- names(table(test3$Release))',
'',
'  inp[,groups] <- 0',
'',
'  for(i in groups){',
'    inp[as.character(inp$Release) == i, i] <- 1',
'  }',
'',
'  inp$inp_final <- paste("1",apply(inp2, 1, paste, collapse=""),sep="")',
'',
'  if(length(groups) > 1){',
'      # make sure factor levels have a release that has detections first. if first release in factor order has zero #detectins, model goes haywire',
'       inp.df <- data.frame(ch = as.character(inp$inp_final), freq = 1, rel = inp$Release, stringsAsFactors = F)',
'',
'      WR.process <- process.data(inp.df, model="CJS", begin.time=1)',
'',
'      WR.ddl <- make.design.data(WR.process)',
'',
'      WR.mark.all <- mark(WR.process, WR.ddl, model.parameters=list(Phi=list(formula=~time),p=list(formula=~time)), silent = T, output = F)',
'',
'      inp.df <- inp.df[inp.df$rel %in% groups_w_detects,]',
'      inp.df$rel <- factor(inp.df$rel, levels = groups_w_detects)',
'',
'      if(length(groups_w_detects) > 1){',
'          WR.process <- process.data(inp.df, model="CJS", begin.time=1, groups = "rel")',
'          WR.ddl <- make.design.data(WR.process)',
'          WR.mark.rel <- mark(WR.process, WR.ddl, model.parameters=list(Phi=list(formula=~time*rel),p=list(formula=~time)), silent = T, output = F)',
'',
'      } else {',
'          WR.process <- process.data(inp.df, model="CJS", begin.time=1)',
'          WR.ddl <- make.design.data(WR.process)',
'          WR.mark.rel <- mark(WR.process, WR.ddl, model.parameters=list(Phi=list(formula=~time),p=list(formula=~time)), silent = T, output = F)',
'      }',
'',
'      WR.surv <- cbind(Release = "ALL",round(WR.mark.all$results$real[1,c("estimate", "se", "lcl", "ucl")] * 100,1))',
'      WR.surv.rel <- cbind(Release = groups_w_detects, round(WR.mark.rel$results$real[seq(from=1,to=length(groups_w_detects)*2,by = 2),',
'                                                                                  c("estimate", "se", "lcl", "ucl")] * 100,1))',
'      WR.surv.rel <- merge(WR.surv.rel, data.frame(Release = groups), all.y = T)',
'      WR.surv.rel[is.na(WR.surv.rel$estimate),"estimate"] <- 0',
'      WR.surv <- rbind(WR.surv, WR.surv.rel)',
'',
'  } else {',
'    inp.df      <- data.frame(ch = as.character(inp$inp_final), freq = 1, stringsAsFactors = F)',
'    WR.process  <- process.data(inp.df, model="CJS", begin.time=1) ',
'    WR.ddl      <- make.design.data(WR.process)',
'    WR.mark.all <- mark(WR.process, WR.ddl, model.parameters=list(Phi=list(formula=~time),p=list(formula=~time)), silent = T, output = F)',
'    WR.surv     <- cbind(Release = c("ALL", groups),round(WR.mark.all$results$real[1,c("estimate", "se", "lcl", "ucl")] * 100,1))',
'  }',
'',
'  WR.surv$Detection_efficiency <- NA',
'  WR.surv[1,"Detection_efficiency"] <- round(WR.mark.all$results$real[gen_loc_sites+1,"estimate"] * 100,1)',
'  WR.surv1 <- WR.surv',
'  colnames(WR.surv1) <- c("Release Group", "Survival (%)", "SE", "95% lower C.I.", "95% upper C.I.", "Detection efficiency (%)")',
'',
paste0('  print(kable(WR.surv1, row.names = F, "html", caption = "3.', table_count, ' Minimum survival to Benicia Bridge East Span (using CJS survival model)") %>%'),
'          kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
'}',
'',
'if(exists("benicia")==T & is.numeric(WR.surv1[1,2])){',
'  # Find mean release time per release group, and ALL',
'  reltimes <- aggregate(list(RelDT = study_tagcodes$release_time), by = list(Release = study_tagcodes$Release), FUN = mean)',
'  reltimes <- rbind(reltimes, data.frame(Release = "ALL", RelDT = mean(study_tagcodes$release_time)))',
'',
'  # Assign whether the results are tentative or final',
'  quality <- "tentative"',
'  if(endtime < as.Date(format(Sys.time(), "%Y-%m-%d"))){',
'    quality <- "final"',
'}',
'',
'  WR.surv       <- merge(WR.surv, reltimes, by = "Release", all.x = T)',
'  WR.surv$RelDT <- as.POSIXct(WR.surv$RelDT, origin = "1970-01-01")',
'  benicia$RelDT <- as.POSIXct(benicia$RelDT)',
'',
'  # remove old benicia record for this studyID',
'  benicia <- benicia[!benicia$StudyID == unique(detects_study$Study_ID),]',
'  benicia <- rbind(benicia, data.frame(WR.surv, StudyID = unique(detects_study$Study_ID), data_quality = quality))',
'',
'  write.csv(benicia, "benicia_surv.csv", row.names = F, quote = F) ',
'}',
'```',
'',
'<br/>',
'',
sep = '\n')
surv_tables <- paste(surv_tables,
surv_tables_tmp,
sep = "\n")
}
return(surv_tables)
}
# Create detection statistics
create_detection_stats <- function(){
detect_stats <- paste('***',
'## _4. Detections statistics at all realtime receivers_',
'***',
'',
sep = '\n')
table_count <- 1
detect_stats <- paste(detect_stats,
'```{r print tables of fish detections, message = FALSE, results= "asis", warning=FALSE}',
'',
paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
'',
'if(nrow(detects_study[is.na(detects_study$DateTime_PST)==F,]) == 0){',
'  "No detections yet"',
'',
'} else {',
'  arrivals <- detects_study %>%',
'              group_by(general_location, TagCode) %>%',
'              summarise(DateTime_PST = min(DateTime_PST)) %>%',
'              arrange(TagCode)',
'',
'  tag_stats <- arrivals %>%',
'               group_by(general_location) %>%',
'               summarise(First_arrival = min(DateTime_PST),',
'                         Mean_arrival = mean(DateTime_PST),',
'                         Last_arrival = max(DateTime_PST),',
'                         Fish_count = length(unique(TagCode))) %>%',
'               mutate(Percent_arrived = round(Fish_count/nrow(study_tagcodes) * 100,2)) %>%',
'               dplyr::left_join(., unique(detects_study[,c("general_location", "river_km")])) %>%',
'               arrange(desc(river_km)) %>%',
'               mutate(First_arrival = format(First_arrival, tz = "Etc/GMT+8"),',
'                      Mean_arrival = format(Mean_arrival, tz = "Etc/GMT+8"),',
'                      Last_arrival = format(Last_arrival, tz = "Etc/GMT+8")) %>%',
'               na.omit()',
'',
'  print(kable(tag_stats, row.names = F,',
paste0('              caption = "4.', table_count, ' Detections for all releases combined",'),
'              "html") %>%',
'          kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
'',
'  for(j in sort(unique(study_tagcodes$Release))){',
'',
'    if(nrow(detects_study[detects_study$Release == j,]) > 0){',
'      arrivals1 <- detects_study %>%',
'                   filter(Release == j) %>%',
'                   group_by(general_location, TagCode) %>%',
'                   summarise(DateTime_PST = min(DateTime_PST)) %>%',
'                   arrange(TagCode)',
'',
'      rel_count <- nrow(study_tagcodes[study_tagcodes$Release == j,])',
'',
'      tag_stats1 <- arrivals1 %>%',
'                    group_by(general_location) %>%',
'                    summarise(First_arrival = min(DateTime_PST),',
'                              Mean_arrival = mean(DateTime_PST),',
'                              Last_arrival = max(DateTime_PST),',
'                              Fish_count = length(unique(TagCode))) %>%',
'                    mutate(Percent_arrived = round(Fish_count/rel_count * 100,2)) %>%',
'                    dplyr::left_join(., unique(detects_study[,c("general_location", "river_km")])) %>%',
'                    arrange(desc(river_km)) %>%',
'                    mutate(First_arrival = format(First_arrival, tz = "Etc/GMT+8"),',
'                           Mean_arrival = format(Mean_arrival, tz = "Etc/GMT+8"),',
'                           Last_arrival = format(Last_arrival, tz = "Etc/GMT+8")) %>%',
'                    na.omit()',
'',
'      final_stats <- kable(tag_stats1, row.names = F,',
paste0('            caption = paste("4.', table_count + 1, '.", j+1 , " Detections for ", j, " release groups", sep = ""),'),
'            "html")',
'      print(kable_styling(final_stats, bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
'',
'    } else {',
paste0('      cat("', '\\', 'n', '\\', 'n', '\\', '\\', 'pagebreak', '\\', 'n")'),
'      print(paste("No detections for",j,"release group yet", sep=" "), quote = F)',
paste0('      cat("', '\\', 'n', '\\', 'n', '\\', '\\', 'pagebreak', '\\', 'n")'),
'    }',
'  }',
'}',
'```',
'',
'<br/>',
'',
sep = '\n')
table_count <- table_count + 2
detect_stats <- paste(detect_stats,
'```{r print tables of fish detections per day, message = FALSE, results= "asis", warning=FALSE}',
'',
paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
'',
'# THIS CODE CHUNK WILL NOT WORK IF USING ONLY ERDDAP DATA, REQUIRES ACCESS TO LOCAL FILES',
'if(nrow(detects_study[is.na(detects_study$DateTime_PST)==F,]) == 0){',
'  "No detections yet"',
'',
'} else {',
'  arrivals <- detects_study %>%',
'              group_by(general_location, TagCode) %>%',
'              summarise(DateTime_PST = min(DateTime_PST)) %>%',
'              mutate(day = as.Date(format(DateTime_PST, "%Y-%m-%d", tz = "Etc/GMT+8")))',
'',
'  gen_locs <- read.csv("realtime_locs.csv", stringsAsFactors = F)',
'',
'  beacon_by_day <- fread("beacon_by_day.csv", stringsAsFactors = F) %>%',
'                   mutate(day = as.Date(day)) %>%',
'                   filter(TagCode == beacon) %>% # Now subset to only look at data for the correct beacon for that day',
'                   filter(day >= as.Date(min(study_tagcodes$release_time)) & ',
'                          day <= endtime) %>% # Now only keep beacon by day for days since fish were released',
'                   dplyr::left_join(., gen_locs[,c("location", "general_location","rkm")], by = "location")',
'',
'  arrivals_per_day <- arrivals %>%',
'                      group_by(day, general_location) %>%',
'                      summarise(New_arrivals = length(TagCode)) %>%',
'                      arrange(general_location) %>% na.omit() %>%',
'                      mutate(day = as.Date(day)) %>%',
'                      dplyr::left_join(unique(beacon_by_day[,c("general_location", "day", "rkm")]),',
'                                       ., by = c("general_location", "day")) %>%',
'                      arrange(general_location, day) %>%',
'                      mutate(day = factor(day)) %>%',
'                      filter(general_location != "Bench_test") %>% # Remove bench test and other NA locations',
'                      filter(!(is.na(general_location))) %>%',
'                      arrange(desc(rkm)) %>% # Change order of data to plot decreasing river_km',
'                      mutate(general_location = factor(general_location, unique(general_location)))',
'',
'  endtime <- min(as.Date(format(Sys.time(), "%Y-%m-%d")),',
'                 max(as.Date(detects_study$release_time)+(as.numeric(detects_study$tag_life)*1.5)))',
'',
'  crosstab <- xtabs(formula = arrivals_per_day$New_arrivals ~ arrivals_per_day$day + arrivals_per_day$general_location,',
'                    addNA =T)',
'  crosstab[is.na(crosstab)] <- ""',
'  crosstab[crosstab==0] <- NA',
'  crosstab <- as.data.frame.matrix(crosstab)',
'',
paste0('  kable(crosstab, align = "c", caption = "4.3 Fish arrivals per day (', "\\", '"NA', "\\", '" means receivers were non-operational)") %>%'),
'    kable_styling(c("striped", "condensed"), font_size = 11, full_width = F, position = "left") %>%',
'    column_spec(column = 1:ncol(crosstab),width_min = "50px",border_left = T, border_right = T) %>%',
'    column_spec(1, bold = T, width_min = "75px")%>%',
'    scroll_box(height = "700px")',
'}',
'',
'rm(list = ls())',
'cleanup(ask = F)',
'```',
'',
'<br/>',
'<br/>',
'',
'***For questions or comments, please contact cyril.michel@noaa.gov***',
sep = "\n")
return(detect_stats)
}
nrows(metadata)
nrow(metadata)
i=1
metadata[i,]
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/Website/Automate Rmd/automate_script.R")
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/Website/Automate Rmd/automate_script.R")
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/Website/Automate Rmd/automate_script.R")
rm(list = ls())
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/Website/Automate Rmd/automate_script.R")
metadata
nrow(metadata>0)
cat(metadata_tmp$script_name)
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/Website/Automate Rmd/automate_script.R")
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/Website/Automate Rmd/automate_script.R")
#__________________________________________________________________________________________________________________
#### Read spreadsheet ####
#__________________________________________________________________________________________________________________
# Check existing .Rmd files in the folder
rmd_files <- data.frame(files = list.files()) %>%
filter(str_detect(files, "Rmd"))
# Read in metadata for study pages and find metadata rows not in the folder yet
metadata <- read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files))
View(metadata)
rm(list = ls())
library(here)
library(tidyverse)
#__________________________________________________________________________________________________________________
#### Read spreadsheet ####
#__________________________________________________________________________________________________________________
# Check existing .Rmd files in the folder
rmd_files <- data.frame(files = list.files()) %>%
filter(str_detect(files, "Rmd"))
rmd_files
# Read in metadata for study pages and find metadata rows not in the folder yet
metadata <- read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files))
View(metadata)
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/Website/Automate Rmd/automate_script.R")
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/Website/Automate Rmd/automate_script.R")
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/Website/Automate Rmd/automate_script.R")
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/Website/Automate Rmd/automate_script.R")
rm(list = ls())
# Load libraries --------------------------------------------------------------------------------------------------
library(here)
library(tidyverse)
# Load libraries --------------------------------------------------------------------------------------------------
library(here)
library(tidyverse)
# Read study spreadsheet ------------------------------------------------------------------------------------------
# Check existing .Rmd files in the folder
rmd_files <- data.frame(files = list.files()) %>%
filter(str_detect(files, "Rmd"))
rmd_files
# Read in metadata for study pages and find metadata rows not in the folder yet
metadata <- read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files))
metadata
# Read study spreadsheet ------------------------------------------------------------------------------------------
# Check existing .Rmd files in the folder
rmd_files <- data.frame(files = list.files()) %>%
filter(str_detect(files, "Rmd"))
rmd_files
# Read in metadata for study pages and find metadata rows not in the folder yet
metadata <- read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files))
# Functions -------------------------------------------------------------------------------------------------------
source("webage_script_functions.R")
getwd()
# Functions -------------------------------------------------------------------------------------------------------
source("webpage_script_functions.R")
# Read study spreadsheet ------------------------------------------------------------------------------------------
# Check existing .Rmd files in the folder
rmd_files <- data.frame(files = list.files()) %>%
filter(str_detect(files, "Rmd"))
rmd_files
# Read study spreadsheet ------------------------------------------------------------------------------------------
# Check existing .Rmd files in the folder
rmd_files <- data.frame(files = list.files()) %>%
filter(str_detect(files, "Rmd"))
rm(list = ls())
# Load libraries --------------------------------------------------------------------------------------------------
library(here)
library(tidyverse)
# Functions -------------------------------------------------------------------------------------------------------
source("webpage_script_functions.R") # load functions save in separate script
# Read study spreadsheet ------------------------------------------------------------------------------------------
# Check existing .Rmd files in the folder
rmd_files <- data.frame(files = list.files()) %>%
filter(str_detect(files, "Rmd"))
rmd_files
read.csv("study_pages.csv")
read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files))
# Read in metadata for study pages and find metadata rows not in the folder yet
metadata <- read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files))
metadata
nrow(metadata > 0)
i = 1
metadata_tmp <- metadata[i,]
metadata_tmp
# Create yaml
yaml <- create_yaml()
# Set up libraries (R code chunk)
setup <- create_setup()
# Set page style
style <- create_style()
# Logos (R code chunk)
logos <- create_logos()
# Picture(R code chunk)
pic <- create_pic(metadata_tmp$picture_file)
# Study header, name and year
study_header  <- create_header(metadata_tmp$study_name, metadata_tmp$study_year, metadata_tmp$study_template)
# Project status
project_status <- create_proj_status(metadata_tmp$study_ID)
# Print table with fish release details (R code chunk)
fish_release <- create_fish_release(metadata_tmp$release_groups, metadata_tmp$release_breaks)
# Map of realtime detections
map <- create_map()
# Detection and flow figurs
detections_figures <- create_detection_figures(metadata_tmp$release_region)
# Survival and routing probability
survival_tables <- create_survival_tables(metadata_tmp$release_region, metadata_tmp$georgiana)
# Detection statistics
detection_stats <- create_detection_stats()
# Write script to .Rmd file
write(c(yaml, setup, style, logos, pic, study_header, project_status, fish_release, map, detections_figures, survival_tables, detection_stats),
file = paste0(here(), "/", metadata_tmp$script_name),
append = FALSE)
# Print file created
cat(metadata_tmp$script_name)
paste0(metadata_tmp$script_name)
cat(paste0(metadata_tmp$script_name), 'created\n'
cat(paste0(metadata_tmp$script_name, 'created\n'))
paste0(metadata_tmp$script_name, 'created\n')
cat(paste0(metadata_tmp$script_name, ' created\n'))
rm(list = ls())
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/1. Automate webpage scripts/create_webpage_scripts.R", echo=TRUE)
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/1. Automate webpage scripts/create_webpage_scripts.R")
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/1. Automate webpage scripts/create_webpage_scripts.R")
rm(list = ls())
# Load libraries --------------------------------------------------------------------------------------------------
library(here)
library(tidyverse)
# Functions -------------------------------------------------------------------------------------------------------
source("webpage_script_functions.R") # load functions save in separate script
# Read study spreadsheet ------------------------------------------------------------------------------------------
# Check existing .Rmd files in the folder
# Read study spreadsheet ------------------------------------------------------------------------------------------
# Check existing .Rmd files in the folder
rmd_files <- data.frame(files = list.files()) %>%
filter(str_detect(files, "Rmd"))
rmd_files
read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files))
metadata
# Read in metadata for study pages and find metadata rows not in the folder yet
metadata <- read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files))
View(metadata)
# Read in metadata for study pages and find metadata rows not in the folder yet
metadata <- read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files))
View(metadata)
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/1. Automate webpage scripts/create_webpage_scripts.R")
rm(list = ls())
# Load libraries --------------------------------------------------------------------------------------------------
library(here)
library(tidyverse)
# Functions -------------------------------------------------------------------------------------------------------
source("webpage_script_functions.R") # load functions save in separate script
# Read study spreadsheet ------------------------------------------------------------------------------------------
# Check existing .Rmd files in the folder
rmd_files <- data.frame(files = list.files()) %>%
filter(str_detect(files, "Rmd"))
read.csv("study_pages.csv")
read.csv("study_pages.csv")
# Read in metadata for study pages and find metadata rows not in the folder yet
metadata <- read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files) | update == Y)
rm(list = ls())
# Load libraries --------------------------------------------------------------------------------------------------
library(here)
library(tidyverse)
# Functions -------------------------------------------------------------------------------------------------------
source("webpage_script_functions.R") # load functions save in separate script
# Read study spreadsheet ------------------------------------------------------------------------------------------
# Check existing .Rmd files in the folder
rmd_files <- data.frame(files = list.files()) %>%
filter(str_detect(files, "Rmd"))
rmd_files
read.csv("study_pages.csv")
read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files) | update == Y)
read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files) | update == "Y")
# Read in metadata for study pages and find metadata rows not in the folder yet
metadata <- read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files) | update == "Y")
metadata
metadata$update[i]
sys.time()
Sys.Date()
Sys.time()
str(Sys.time())
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/1. Automate webpage scripts/create_webpage_scripts.R")
metadata
?write.csv
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/1. Automate webpage scripts/create_webpage_scripts.R")
cat('All files in **study_pages.csv** already exist.')
cat('All files in ***study_pages.csv*** already exist.')
cat('All files in "study_pages.csv" already exist.')
?write.csv
row.names(metadata)
metadata
rm(list = ls())
# Load libraries --------------------------------------------------------------------------------------------------
library(here)
library(tidyverse)
# Functions -------------------------------------------------------------------------------------------------------
source("webpage_script_functions.R") # load functions save in separate script
# Read study spreadsheet ------------------------------------------------------------------------------------------
# Check existing .Rmd files in the folder
rmd_files <- data.frame(files = list.files()) %>%
filter(str_detect(files, "Rmd"))
# Read in metadata for study pages and find metadata rows not in the folder yet
metadata <- read.csv("study_pages.csv") %>%
filter(!(script_name %in% rmd_files$files) | update == "Y")
row.names(metadata)
row.names(metadata) <- NULL
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/1. Automate webpage scripts/create_webpage_scripts.R")
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/1. Automate webpage scripts/create_webpage_scripts.R")
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/1. Automate webpage scripts/create_webpage_scripts.R")
source("C:/Users/pgcar/Google Drive/1 Work/1 NOAA UCSC AT/1 Projects/1. Automate webpage scripts/create_webpage_scripts.R")
