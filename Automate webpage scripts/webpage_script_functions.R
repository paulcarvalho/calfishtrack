# webpage_script_functions.R
# 
# Author: Paul Carvalho (paul.carvalho@noaa.gov)
#
# Description: Functions used in create_webpage_scripts.R

# Create yaml code for html header
create_yaml <- function(){
   paste("---",
         "title: CalFishTrack",
         "",
         "output:",
         "   html_document:",
         "     code_folding: hide",
         "     toc: true",
         "     toc_float: true",
         "     includes:",
         "        in_header: GA_Script.html",
         "---",
         sep = "\n")
}

# Create r code chunk that loads libraries
create_setup <- function(){
   paste("",
         "```{r setup, include=FALSE}",
         "knitr::opts_chunk$set(echo = TRUE)",
         "library(knitr)",
         "library(kableExtra)",
         "library(lubridate)",
         "library(data.table)",
         "library(ggplot2)",
         "library(scales)",
         "library(viridis)",
         "library(forcats)",
         "library(RColorBrewer)",
         "```",
         sep = "\n")
}

# Set style of the html
create_style <- function(){
   paste("",
         "<style>",
         "   p.caption {",
         "      font-size: 1.5em;",
         "   }",
         "caption {",
         "   font-size: 1.5em;",
         "}",
         "</style>",
         "#  *Central Valley Enhanced*",
         "#  *Acoustic Tagging Project*",
         sep = "\n")
}

# Create r code chunk that adds logos to webpages
create_logos <- function(){
   paste("",
         "```{r logos, echo=FALSE, cache=TRUE}",
         'htmltools::img(src = knitr::image_uri("../data/logos.jpg"),',
         "               alt = 'logo',",
         "               style = 'position:absolute; top:10px; right:0px; width:200px;')",
         "```",
         "",
         "<br/>",
         "<br/>",
         sep = "\n")
}

# Create r code chunk that adds study picture
create_pic <- function(pic_file){
   paste("",
         "```{r study picture, echo=FALSE, cache=TRUE}",
         paste0('htmltools::img(src = knitr::image_uri("',pic_file,'"))'),
         "```",
         "",
         "<br/>",
         "<br/>",
         sep = "\n")
}

# Write markdown text for the header (study name, year, and template link)
create_header <- function(study_name, study_year, template_file){
   paste("",
         paste0("# **", study_name, "**"),
         "",
         paste0("## ", study_year, " Season (PROVISIONAL DATA)"),
         "",
         "<br/>",
         "",
         paste0("#### **Telemetry Study Template** for this study can be found [here](",
                template_file, ")"),
         "",
         "<br/>",
         sep = "\n")
}

# Create r code chunk that downloads study detections and adds project status
create_proj_status <- function(study){
   project_status1 <- paste("",
                            "***",
                            "## _1. Project Status_",
                            "***",
                            sep = "\n")
   
   project_status2 <- paste("",
                            '```{r download detections, warning = F, message = F, class.source = "fold-hide", echo = F}',
                            "",
                            paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep="', '\\', '\\"', "), ", '"', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
                            "",
                            "library(knitr)",
                            "library(kableExtra)",
                            "library(lubridate)",
                            "library(data.table)",
                            "library(ggplot2)",
                            "library(RMark)",
                            "library(scales)",
                            "library(viridis)",
                            "library(forcats)",
                            "library(reshape2)",
                            "library(png)",
                            "library(dataRetrieval)",
                            "library(rerddap)",
                            "library(plotly)",
                            "",
                            paste0('study <- "', study, '"'),
                            "",
                            'detects_study <- fread("study_detections.csv", stringsAsFactors = F,',
                            '                       colClasses = c(DateTime_PST = "character", RelDT = "character")) %>%',
                            '   filter(Study_ID == study) %>%',
                            '   mutate(DateTime_PST = as.POSIXct(DateTime_PST, format = "%Y-%m-%d %H:%M:%S", tz="Etc/GMT+8"),',
                            '          release_time = as.POSIXct(RelDT, format = "%Y-%m-%d %H:%M:%S", tz="Etc/GMT+8")) %>%',
                            '   rename(., weight=Weight, length=Length, release_rkm=Rel_rkm, release_location=Rel_loc, river_km=rkm)',
                            "",
                            'latest <- read.csv("latest_download.csv", stringsAsFactors = F)$x',
                            "",
                            "##################################################################################################################",
                            '#### TO RUN THE FOLLOWING CODE CHUNKS FROM HERE ON DOWN USING R ERDDAP, UN-COMMENT THESE NEXT 9 LINES OF CODE ####',
                            '##################################################################################################################',
                            "# cache_delete_all()",
                            paste0("# query = paste(", "'&'", ",'Study_ID',", "'", "=", '"', "'", ", study, ", "'", '"', "'", ", sep = ", "''", ")"),
                            '# datafile=URLencode(paste("https://oceanview.pfeg.noaa.gov/erddap/tabledap/","FEDcalFishTrack",".csv?",query,sep = ""))',
                            '# options(url.method = "libcurl", download.file.method = "libcurl", timeout = 180)',
                            '# detects_study <- data.frame(read.csv(datafile,row.names = NULL, stringsAsFactors = F))',
                            '# detects_study <- detects_study[-1,]',
                            '# detects_study$DateTime_PST <- as.POSIXct(detects_study$local_time, format = "%Y-%m-%d %H:%M:%S", "Etc/GMT+8")',
                            '# detects_study$release_time <- as.POSIXct(detects_study$release_time, format = "%Y-%m-%d %H:%M:%S", "Etc/GMT+8")',
                            '# detects_study$river_km <- as.numeric(detects_study$river_km)',
                            '##################################################################################################################',
                            "",
                            "```",
                            sep = "\n")
   
   project_status3 <- paste("",
                            '***`r if (nrow(detects_study) == 0){ anicon::nia("Study has not yet begun", size = 1, colour = "red")',
                            '}else if (min(detects_study$release_time) > Sys.time()){ anicon::nia("Study has not yet begun", size = 1, colour = "red")',
                            '}else if (max(as.Date(detects_study$release_time)+(as.numeric(detects_study$tag_life)*1.5)) < Sys.Date()) { anicon::nia(paste("Study is complete, all tags are no longer active as of",max(as.Date(detects_study$release_time)+(as.numeric(detects_study$tag_life)*1.5))), size = 1, colour = "red")',
                            '}else{anicon::nia(paste("Study is in progress. Data current as of", latest), size = 1, colour = "red")',
                            '}`. All times in Pacific Standard Time.***',
                            "",
                            sep = "\n")
   
   project_status <- paste(project_status1,
                           project_status2,
                           project_status3,
                           sep = "\n")
   
   return(project_status)   
}

# Create r code chunk with fish release information
create_fish_release <- function(release_groups, release_breaks){
   fish_release1 <- paste("",
                          "```{r print table with fish release details, warning= F, message = F, results='asis', echo = F}",
                          "if (nrow(detects_study) == 0){",
                          '   cat("Study has not yet begun  ")',
                          "} else {",
                          "   if (min(detects_study$release_time) > Sys.time()){",
                          '      cat("Study has not yet begun, below data is a placeholder:  ")',
                          "   }",
                          "   if (min(detects_study$release_time) < Sys.time()){",
                          '      cat(paste("Study began on ", min(detects_study$release_time), ", see tagging details below:", sep = ""))',
                          "   }",
                          "",
                          "   ######################################",
                          "   #### RELEASE GROUPS ASSIGNED HERE ####",
                          "   ######################################",
                          sep = "\n")
   
   if(!(is.na(release_breaks))){
      rel_groups <- trimws(unlist(strsplit(release_groups, split = ",")), which = "both")
      rel_breaks <- trimws(unlist(strsplit(release_breaks, split = ",")), which = "both")
      
      fish_release2 <- paste0("   detects_study$Release <- ", '"', rel_groups[1], '"')
      
      if(length(rel_groups) > 1){
         for(i in 1:length(rel_breaks)){
            fish_release2 <- paste(fish_release2,
                                   paste0("   detects_study[detects_study$release_time > as.POSIXct(", '"', rel_breaks[i], '"', '), "Release"] <- "', 
                                          rel_groups[i+1], '"'),
                                   sep = "\n")
         }
      }
   } else {
      fish_release2 <- paste0("   detects_study$Release <- detects_study$release_location")
   }
   
   fish_release3 <- paste("",
                          '   study_tagcodes <- unique(detects_study[,c("TagCode", "release_time", "weight", "length", "release_rkm",',
                          '                                             "release_location", "Release")])',
                          '',
                          '   release_stats <- study_tagcodes %>%',
                          '      group_by(Release) %>%',
                          '      summarise(First_release_time = min(release_time),',
                          '                Last_release_time = max(release_time),',
                          '                Number_fish_released = length(unique(TagCode)),',
                          '                Release_location = head(release_location, 1),',
                          '                Release_rkm = head(release_rkm,1),',
                          '                Mean_length = mean(length, na.rm=T),',
                          '                Mean_weight = mean(weight, na.rm=T)) %>%',
                          '      mutate(Mean_length = round(Mean_length, 1),',
                          '             Mean_weight = round(Mean_weight, 1),',
                          '             First_release_time = format(First_release_time, tz = "Etc/GMT+8"),',
                          '             Last_release_time = format(Last_release_time, tz = "Etc/GMT+8")) %>%',
                          '      arrange(First_release_time)',
                          '}',
                          'kable(release_stats, format = "html", row.names = F) %>%',
                          '   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left")',
                          '```',
                          '',
                          "<br/>",
                          sep = "\n")
   
   fish_release <- paste(fish_release1, fish_release2, fish_release3, sep = "\n")
   return(fish_release)
}

# Create r code chunk to generate map of realtime detections
create_map <- function(){
   map  <- paste("",
                 '***',
                 '## _2. Real-time Fish Detections_',
                 '***',
                 '',
                 '```{r print map of fish detections, message = FALSE, results= "asis", warning=FALSE, fig.cap="2.1 Map of unique fish detections at operational realtime detection locations"}',
                 '',
                 'library(leaflet)',
                 'library(maps)',
                 'library(htmlwidgets)',
                 'library(leaflet.extras)',
                 paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
                 '',
                 '## THIS CODE CHUNK WILL NOT WORK IF USING ONLY ERDDAP DATA, REQUIRES ACCESS TO LOCAL FILES',
                 'if (nrow(detects_study[is.na(detects_study$DateTime_PST)==F,]) == 0){',
                 '   "No detections yet"',
                 '} else {',
                 '',
                 '   gen_locs <- read.csv("realtime_locs.csv", stringsAsFactors = F)',
                 '',
                 '   endtime <- min(as.Date(format(Sys.time(), "%Y-%m-%d")),',
                 '                  max(as.Date(detects_study$release_time)+(as.numeric(detects_study$tag_life)*1.5)))',
                 '',
                 '   beacon_by_day <- fread("beacon_by_day.csv", stringsAsFactors = F) %>%',
                 '      mutate(day = as.Date(day)) %>%',
                 '      # Subset to only look at data for the correct beacon for that day',
                 '      filter(TagCode == beacon)  %>% ',
                 '      # Only keep beacon by day for days since fish were released',
                 '      filter(day >= as.Date(min(study_tagcodes$release_time)) & day <= endtime) %>%',
                 '      dplyr::left_join(., gen_locs[,c("location", "general_location","rkm")], by = "location")',
                 '',
                 '   arrivals_per_day <- detects_study %>%',
                 '      group_by(general_location, TagCode) %>%',
                 '      summarise(DateTime_PST = min(DateTime_PST, na.rm = T)) %>%',
                 '      arrange(TagCode, general_location) %>%',
                 '      mutate(day = as.Date(format(DateTime_PST, "%Y-%m-%d", tz = "Etc/GMT+8"))) %>%',
                 '      group_by(day, general_location) %>%',
                 '      summarise(New_arrivals = length(TagCode)) %>%',
                 '      na.omit() %>%',
                 '      mutate(day = as.Date(day)) %>%',
                 '      dplyr::left_join(unique(beacon_by_day[,c("general_location", "day", "rkm")]), ., ',
                 '                       by = c("general_location", "day")) %>%',
                 '      arrange(general_location, day) %>%',
                 '      mutate(day = as.factor(day)) %>%',
                 '      filter(general_location != "Bench_test") %>% # Remove bench test',
                 '      filter(!(is.na(general_location))) # Remove NA locations',
                 '',
                 '   ## Remove sites that were not operation the whole time',
                 '   #### FOR THE SEASONAL SURVIVAL PAGE, KEEP ALL SITES SINCE PEOPLE WANT TO SEE DETECTIONS OF LATER FISH AT NEWLY ',
                 '   #### DEPLOYED SPOTS',
                 '   gen_locs_days_in_oper <- arrivals_per_day %>%',
                 '      group_by(general_location) %>%',
                 '      summarise(days_in_oper = length(day))',
                 '   #gen_locs_days_in_oper <- gen_locs_days_in_oper[gen_locs_days_in_oper$days_in_oper ==',
                 '   #                                               max(gen_locs_days_in_oper$days_in_oper),]',
                 '   arrivals_per_day_in_oper <- arrivals_per_day %>%',
                 '      filter(general_location %in% gen_locs_days_in_oper$general_location)',
                 '',
                 '   fish_per_site <- arrivals_per_day_in_oper %>%',
                 '      group_by(general_location) %>%',
                 '      summarise(fish_count = sum(New_arrivals, na.rm=T))',
                 '',
                 '   gen_locs_mean_coords <- gen_locs %>%',
                 '      filter(is.na(stop) & general_location %in% fish_per_site$general_location) %>%',
                 '      group_by(general_location) %>%',
                 '      summarise(latitude = mean(latitude), # estimate mean lat and lons for each genloc',
                 '                longitude = mean(longitude))',
                 '',
                 '   fish_per_site <- merge(fish_per_site, gen_locs_mean_coords)',
                 '   icons <- awesomeIcons(iconColor = "lightblue",',
                 '                         text = fish_per_site$fish_count)',
                 '',
                 '   leaflet(data = fish_per_site) %>%',
                 '      addProviderTiles("Esri.WorldStreetMap", group = "Map") %>%',
                 '      addProviderTiles("Esri.WorldImagery", group = "Satellite") %>% ',
                 '      addProviderTiles("Esri.WorldShadedRelief", group = "Relief") %>%',
                 '      # Marker data are from the sites data frame. We need the ~ symbols',
                 '      # to indicate the columns of the data frame.',
                 '      addMarkers(~longitude, ~latitude, label = ~fish_count, group = "Receiver Sites", popup = ~general_location,',
                 '                 labelOptions = labelOptions(noHide = T, textsize = "15px")) %>% ',
                 '      addScaleBar(position = "bottomleft") %>%',
                 '      addLayersControl(baseGroups = c("Street Map", "Satellite", "Relief"),',
                 '                       options = layersControlOptions(collapsed = FALSE))',
                 
                 '}',
                 '```',
                 '',
                 '<br/>',
                 sep = "\n")
   
}

# Create figures displaying fish detections and flows across time
create_detection_figures <- function(release_region){
   fig_count      <- 1 # initialize figure count
   detection_figs <- paste("", sep = "\n") # initialize detection script
   
   # Salt Creek
   if(release_region == 1){ 
      fig_count <- fig_count + 1
      detection_figs_tmp <- paste(paste0('```{r print figure of fish detections at ', 'Salt Creek', ', message = FALSE, warning=F, fig.height = 6, fig.width = 10, out.extra=',"'style=",
                                         '"background-color: #000000; padding:3px"',"', fig.cap=",
                                         '"2.',fig_count,' ', 'Detections at Salt Creek versus Sacramento River flows at Bend Bridge for duration of tag life','"}'),
                                  '',
                                  'library(tidyr)',
                                  '',
                                  paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
                                  '',
                                  paste0('detects_', fig_count, ' <- detects_study %>% filter(general_location == "', 'Blw_Salt_RT', '")'),
                                  '',
                                  paste0('if(nrow(detects_', fig_count,') == 0){'),
                                  '   plot(1:2, type = "n", xlab = "",xaxt = "n", yaxt = "n", ylab = "Number of fish arrivals per day")',
                                  '   text(1.5,1.5, labels = "NO DETECTIONS YET", cex = 2)',
                                  '} else {',
                                  paste0('  detects_', fig_count, ' <- detects_', fig_count, ' %>%'),
                                  paste0('    dplyr::left_join(., detects_', fig_count, ' %>%'),
                                  '                        group_by(TagCode) %>% ',
                                  '                        summarise(first_detect = min(DateTime_PST))) %>%',
                                  '                        mutate(Day = as.Date(as.Date(first_detect, "Etc/GMT+8")))',
                                  '',
                                  paste0('  starttime <- as.Date(min(detects_', fig_count, '$release_time), "Etc/GMT+8")'),
                                  '',
                                  '  # Endtime should be either now, or end of predicted tag life, whichever comes first',
                                  '  endtime <- min(as.Date(format(Sys.time(), "%Y-%m-%d")),',
                                  '                 max(as.Date(detects_study$release_time)+(as.numeric(detects_study$tag_life))))',
                                  '',
                                  '  daterange <- data.frame(Day = seq.Date(from = starttime, to = endtime, by = "day"))',
                                  '',
                                  '  rels            <- unique(study_tagcodes$Release)',
                                  '  rel_num         <- length(rels)',
                                  paste0('  rels_no_detects <- as.character(rels[!(rels %in% unique(detects_', fig_count, '$Release))])'),
                                  '',
                                  paste0('  tagcount1 <- detects_', fig_count, ' %>%'),
                                  '               group_by(Day, Release) %>%',
                                  '               summarise(unique_tags = length(unique(TagCode))) %>%',
                                  '               spread(Release, unique_tags)',
                                  '',
                                  '  daterange1 <- merge(daterange, tagcount1, all.x=T)',
                                  '  daterange1[is.na(daterange1)] <- 0',
                                  '',
                                  '  if(length(rels_no_detects)>0){',
                                  '    for(i in rels_no_detects){',
                                  '      daterange1 <- cbind(daterange1, x=NA)',
                                  '      names(daterange1)[names(daterange1) == "x"] <- paste(i)',
                                  '    }',
                                  '  }',
                                  '',
                                  '  # Download flow data',
                                  paste0('  flow_day <- readNWISuv(siteNumbers = "', '11377100', '", parameterCd="00060", startDate = starttime, '),
                                  '                         endDate = endtime+1) %>%',
                                  '                  mutate(Day = as.Date(format(dateTime, "%Y-%m-%d"))) %>%',
                                  '                  group_by(Day) %>%',
                                  '                  summarise(parameter_value = mean(X_00060_00000))',
                                  '',
                                  '  ## reorder columns in alphabetical order so its coloring in barplots is consistent',
                                  '  daterange2 <- daterange1[,order(colnames(daterange1))] %>%',
                                  '                dplyr::left_join(., flow_day, by = "Day")',
                                  '  rownames(daterange2) <- daterange2$Day',
                                  '  daterange2$Date      <- daterange2$Day',
                                  '  daterange2$Day       <- NULL',
                                  '  daterange2_flow      <- daterange2 %>% select(Date, parameter_value)',
                                  '  daterange3           <- melt(daterange2[,!(names(daterange2) %in% c("parameter_value"))], ',
                                  '                               id.vars = "Date", variable.name = ".")',
                                  '  daterange3$.         <- factor(daterange3$., levels = sort(unique(daterange3$.), decreasing = T))',
                                  '',
                                  '  par(mar=c(6, 5, 2, 5) + 0.1)',
                                  '  ay <- list(',
                                  '    overlaying = "y",',
                                  '    nticks = 5,',
                                  '    color = "#947FFF",',
                                  '    side = "right",',
                                  paste0('    title = "Flow (cfs) at ', 'Bend Bridge', '",'),
                                  '    automargin = TRUE',
                                  '  )',
                                  '',
                                  '  plot_ly(daterange3, width = 900, height = 600, dynamicTicks = TRUE) %>%',
                                  '          add_bars(x = ~Date, y = ~value, color = ~.) %>%',
                                  '          add_annotations(text="Release (click on legend items to isolate)", xref="paper", yref="paper",',
                                  '                          x=0.01, xanchor="left",',
                                  '                          y=1.056, yanchor="top",    # Same y as legend below',
                                  '                          legendtitle=TRUE, showarrow=FALSE ) %>%',
                                  '          add_lines(x=~daterange2_flow$Date, ',
                                  '                    y=~daterange2_flow$parameter_value, ',
                                  '                    line = list(color = alpha("#947FFF", alpha = 0.5)), yaxis="y2", showlegend=FALSE, ',
                                  '                    inherit=FALSE) %>%',
                                  '          layout(yaxis2 = ay,showlegend = T, ',
                                  '          barmode = "stack",',
                                  '          xaxis = list(title = "Date", mirror=T,ticks="outside",showline=T), ',
                                  '          yaxis = list(title = "Number of fish arrivals per day", mirror=T,ticks="outside",showline=T),',
                                  '          legend = list(orientation = "h",x = 0.34, y = 1.066),',
                                  '          margin=list(l = 50,r = 100,b = 50,t = 50))',
                                  '',
                                  '}',
                                  '```',
                                  '',
                                  '<br/>',
                                  sep = "\n")
      
      detection_figs <- paste(detection_figs,
                              detection_figs_tmp,
                              sep = "\n")
   }
   
   # Butte Cite Bridge
   if(release_region == 1 | release_region == 2){
      fig_count <- fig_count + 1
      detection_figs_tmp <- paste("",
                                  paste0('```{r print figure of fish detections at ', 'Butte', ', message = FALSE, warning=F, fig.height = 6, fig.width = 10, out.extra=',"'style=",
                                         '"background-color: #000000; padding:3px"',"', fig.cap=",
                                         '"2.',fig_count,' ', 'Detections at Butte City Bridge versus Sacramento River flows at Bend Bridge for duration of tag life','"}'),
                                  '',
                                  'library(tidyr)',
                                  '',
                                  paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
                                  '',
                                  paste0('detects_', fig_count, ' <- detects_study %>% filter(general_location == "', 'ButteBrRT', '")'),
                                  '',
                                  paste0('if(nrow(detects_', fig_count,') == 0){'),
                                  '   plot(1:2, type = "n", xlab = "",xaxt = "n", yaxt = "n", ylab = "Number of fish arrivals per day")',
                                  '   text(1.5,1.5, labels = "NO DETECTIONS YET", cex = 2)',
                                  '} else {',
                                  paste0('  detects_', fig_count, ' <- detects_', fig_count, ' %>%'),
                                  paste0('    dplyr::left_join(., detects_', fig_count, ' %>%'),
                                  '                        group_by(TagCode) %>% ',
                                  '                        summarise(first_detect = min(DateTime_PST))) %>%',
                                  '                        mutate(Day = as.Date(as.Date(first_detect, "Etc/GMT+8")))',
                                  '',
                                  paste0('  starttime <- as.Date(min(detects_', fig_count, '$release_time), "Etc/GMT+8")'),
                                  '',
                                  '  # Endtime should be either now, or end of predicted tag life, whichever comes first',
                                  '  endtime <- min(as.Date(format(Sys.time(), "%Y-%m-%d")),',
                                  '                 max(as.Date(detects_study$release_time)+(as.numeric(detects_study$tag_life))))',
                                  '',
                                  '  daterange <- data.frame(Day = seq.Date(from = starttime, to = endtime, by = "day"))',
                                  '',
                                  '  rels            <- unique(study_tagcodes$Release)',
                                  '  rel_num         <- length(rels)',
                                  paste0('  rels_no_detects <- as.character(rels[!(rels %in% unique(detects_', fig_count, '$Release))])'),
                                  '',
                                  paste0('  tagcount1 <- detects_', fig_count, ' %>%'),
                                  '               group_by(Day, Release) %>%',
                                  '               summarise(unique_tags = length(unique(TagCode))) %>%',
                                  '               spread(Release, unique_tags)',
                                  '',
                                  '  daterange1 <- merge(daterange, tagcount1, all.x=T)',
                                  '  daterange1[is.na(daterange1)] <- 0',
                                  '',
                                  '  if(length(rels_no_detects)>0){',
                                  '    for(i in rels_no_detects){',
                                  '      daterange1 <- cbind(daterange1, x=NA)',
                                  '      names(daterange1)[names(daterange1) == "x"] <- paste(i)',
                                  '    }',
                                  '  }',
                                  '',
                                  '  # Download flow data',
                                  paste0('  flow_day <- readNWISuv(siteNumbers = "', '11377100', '", parameterCd="00060", startDate = starttime, '),
                                  '                         endDate = endtime+1) %>%',
                                  '                  mutate(Day = as.Date(format(dateTime, "%Y-%m-%d"))) %>%',
                                  '                  group_by(Day) %>%',
                                  '                  summarise(parameter_value = mean(X_00060_00000))',
                                  '',
                                  '  ## reorder columns in alphabetical order so its coloring in barplots is consistent',
                                  '  daterange2 <- daterange1[,order(colnames(daterange1))] %>%',
                                  '                dplyr::left_join(., flow_day, by = "Day")',
                                  '  rownames(daterange2) <- daterange2$Day',
                                  '  daterange2$Date      <- daterange2$Day',
                                  '  daterange2$Day       <- NULL',
                                  '  daterange2_flow      <- daterange2 %>% select(Date, parameter_value)',
                                  '  daterange3           <- melt(daterange2[,!(names(daterange2) %in% c("parameter_value"))], ',
                                  '                               id.vars = "Date", variable.name = ".")',
                                  '  daterange3$.         <- factor(daterange3$., levels = sort(unique(daterange3$.), decreasing = T))',
                                  '',
                                  '  par(mar=c(6, 5, 2, 5) + 0.1)',
                                  '  ay <- list(',
                                  '    overlaying = "y",',
                                  '    nticks = 5,',
                                  '    color = "#947FFF",',
                                  '    side = "right",',
                                  paste0('    title = "Flow (cfs) at ', 'Bend Bridge', '",'),
                                  '    automargin = TRUE',
                                  '  )',
                                  '',
                                  '  plot_ly(daterange3, width = 900, height = 600, dynamicTicks = TRUE) %>%',
                                  '          add_bars(x = ~Date, y = ~value, color = ~.) %>%',
                                  '          add_annotations(text="Release (click on legend items to isolate)", xref="paper", yref="paper",',
                                  '                          x=0.01, xanchor="left",',
                                  '                          y=1.056, yanchor="top",    # Same y as legend below',
                                  '                          legendtitle=TRUE, showarrow=FALSE ) %>%',
                                  '          add_lines(x=~daterange2_flow$Date, ',
                                  '                    y=~daterange2_flow$parameter_value, ',
                                  '                    line = list(color = alpha("#947FFF", alpha = 0.5)), yaxis="y2", showlegend=FALSE, ',
                                  '                    inherit=FALSE) %>%',
                                  '          layout(yaxis2 = ay,showlegend = T, ',
                                  '          barmode = "stack",',
                                  '          xaxis = list(title = "Date", mirror=T,ticks="outside",showline=T), ',
                                  '          yaxis = list(title = "Number of fish arrivals per day", mirror=T,ticks="outside",showline=T),',
                                  '          legend = list(orientation = "h",x = 0.34, y = 1.066),',
                                  '          margin=list(l = 50,r = 100,b = 50,t = 50))',
                                  '',
                                  '}',
                                  '```',
                                  '',
                                  '<br/>',
                                  sep = "\n")
      
      detection_figs <- paste(detection_figs,
                              detection_figs_tmp,
                              sep = "\n")
   }
   
   # Tower Bridge
   if(release_region >= 1 & release_region <=3 ){
      fig_count <- fig_count + 1
      detection_figs_tmp <- paste("",
                                  paste0('```{r print figure of fish detections at ', 'Tower Bridge', ', message = FALSE, warning=F, fig.height = 6, fig.width = 10, out.extra=',"'style=",
                                         '"background-color: #000000; padding:3px"',"', fig.cap=",
                                         '"2.',fig_count,' ', 'Detections at Tower Bridge (downtown Sacramento) versus Sacramento River flows at Wilkins Slough for duration of tag life','"}'),
                                  '',
                                  'library(tidyr)',
                                  '',
                                  paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
                                  '',
                                  paste0('detects_', fig_count, ' <- detects_study %>% filter(general_location == "', 'TowerBridge', '")'),
                                  '',
                                  paste0('if(nrow(detects_', fig_count,') == 0){'),
                                  '   plot(1:2, type = "n", xlab = "",xaxt = "n", yaxt = "n", ylab = "Number of fish arrivals per day")',
                                  '   text(1.5,1.5, labels = "NO DETECTIONS YET", cex = 2)',
                                  '} else {',
                                  paste0('  detects_', fig_count, ' <- detects_', fig_count, ' %>%'),
                                  paste0('    dplyr::left_join(., detects_', fig_count, ' %>%'),
                                  '                        group_by(TagCode) %>% ',
                                  '                        summarise(first_detect = min(DateTime_PST))) %>%',
                                  '                        mutate(Day = as.Date(as.Date(first_detect, "Etc/GMT+8")))',
                                  '',
                                  paste0('  starttime <- as.Date(min(detects_', fig_count, '$release_time), "Etc/GMT+8")'),
                                  '',
                                  '  # Endtime should be either now, or end of predicted tag life, whichever comes first',
                                  '  endtime <- min(as.Date(format(Sys.time(), "%Y-%m-%d")),',
                                  '                 max(as.Date(detects_study$release_time)+(as.numeric(detects_study$tag_life))))',
                                  '',
                                  '  daterange <- data.frame(Day = seq.Date(from = starttime, to = endtime, by = "day"))',
                                  '',
                                  '  rels            <- unique(study_tagcodes$Release)',
                                  '  rel_num         <- length(rels)',
                                  paste0('  rels_no_detects <- as.character(rels[!(rels %in% unique(detects_', fig_count, '$Release))])'),
                                  '',
                                  paste0('  tagcount1 <- detects_', fig_count, ' %>%'),
                                  '               group_by(Day, Release) %>%',
                                  '               summarise(unique_tags = length(unique(TagCode))) %>%',
                                  '               spread(Release, unique_tags)',
                                  '',
                                  '  daterange1 <- merge(daterange, tagcount1, all.x=T)',
                                  '  daterange1[is.na(daterange1)] <- 0',
                                  '',
                                  '  if(length(rels_no_detects)>0){',
                                  '    for(i in rels_no_detects){',
                                  '      daterange1 <- cbind(daterange1, x=NA)',
                                  '      names(daterange1)[names(daterange1) == "x"] <- paste(i)',
                                  '    }',
                                  '  }',
                                  '',
                                  '  # Download flow data',
                                  paste0('  flow_day <- readNWISuv(siteNumbers = "', '11390500', '", parameterCd="00060", startDate = starttime, '),
                                  '                         endDate = endtime+1) %>%',
                                  '                  mutate(Day = as.Date(format(dateTime, "%Y-%m-%d"))) %>%',
                                  '                  group_by(Day) %>%',
                                  '                  summarise(parameter_value = mean(X_00060_00000))',
                                  '',
                                  '  ## reorder columns in alphabetical order so its coloring in barplots is consistent',
                                  '  daterange2 <- daterange1[,order(colnames(daterange1))] %>%',
                                  '                dplyr::left_join(., flow_day, by = "Day")',
                                  '  rownames(daterange2) <- daterange2$Day',
                                  '  daterange2$Date      <- daterange2$Day',
                                  '  daterange2$Day       <- NULL',
                                  '  daterange2_flow      <- daterange2 %>% select(Date, parameter_value)',
                                  '  daterange3           <- melt(daterange2[,!(names(daterange2) %in% c("parameter_value"))], ',
                                  '                               id.vars = "Date", variable.name = ".")',
                                  '  daterange3$.         <- factor(daterange3$., levels = sort(unique(daterange3$.), decreasing = T))',
                                  '',
                                  '  par(mar=c(6, 5, 2, 5) + 0.1)',
                                  '  ay <- list(',
                                  '    overlaying = "y",',
                                  '    nticks = 5,',
                                  '    color = "#947FFF",',
                                  '    side = "right",',
                                  paste0('    title = "Flow (cfs) at ', 'Wilkins Slough', '",'),
                                  '    automargin = TRUE',
                                  '  )',
                                  '',
                                  '  plot_ly(daterange3, width = 900, height = 600, dynamicTicks = TRUE) %>%',
                                  '          add_bars(x = ~Date, y = ~value, color = ~.) %>%',
                                  '          add_annotations(text="Release (click on legend items to isolate)", xref="paper", yref="paper",',
                                  '                          x=0.01, xanchor="left",',
                                  '                          y=1.056, yanchor="top",    # Same y as legend below',
                                  '                          legendtitle=TRUE, showarrow=FALSE ) %>%',
                                  '          add_lines(x=~daterange2_flow$Date, ',
                                  '                    y=~daterange2_flow$parameter_value, ',
                                  '                    line = list(color = alpha("#947FFF", alpha = 0.5)), yaxis="y2", showlegend=FALSE, ',
                                  '                    inherit=FALSE) %>%',
                                  '          layout(yaxis2 = ay,showlegend = T, ',
                                  '          barmode = "stack",',
                                  '          xaxis = list(title = "Date", mirror=T,ticks="outside",showline=T), ',
                                  '          yaxis = list(title = "Number of fish arrivals per day", mirror=T,ticks="outside",showline=T),',
                                  '          legend = list(orientation = "h",x = 0.34, y = 1.066),',
                                  '          margin=list(l = 50,r = 100,b = 50,t = 50))',
                                  '',
                                  '}',
                                  '```',
                                  '',
                                  '<br/>',
                                  sep = "\n")
      
      detection_figs <- paste(detection_figs,
                              detection_figs_tmp,
                              sep = "\n")
   }
   
   # Old and Middle Rivers
   if(release_region >= 1 & release_region <= 4){
      fig_count <- fig_count + 1
      detection_figs_tmp <- paste("",
                                  paste0('```{r print figure of fish detections at ', 'Old and Middle Rivers', ', message = FALSE, warning=F, fig.height = 6, fig.width = 10, out.extra=',"'style=",
                                         '"background-color: #000000; padding:3px"',"', fig.cap=",
                                         '"2.',fig_count,' ', '(BETA) Detections in the Old and Middle rivers (OMR) for duration of tag life (top) and flow at OMR (bottom). Arrows indicate fish movement.','"}'),
                                  '',
                                  'library(dplyr)',
                                  'library(CDECRetrieve)',
                                  '',
                                  paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
                                  '',
                                  'recv_locs <- read.csv("realtime_locs.csv")',
                                  '',
                                  paste0('detects_', fig_count, ' <- detects_study %>% filter(general_location %in% c("Old_River_Quimby", "Holland_Cut_Quimby", "Old River", "MiddleRiver", "Clifton_Court_US_Radial_Gates", "SWP_radial_gates_DS", "SWP_radial_gates_US", "CVP_Trash_Rack_1", "CVP_Tank", "SWP_intake", "Clifton_Court_Intake_Canal"))'),
                                  '',
                                  paste0('if(nrow(detects_', fig_count, ') > 0){'),
                                  '  # Save the last detection at each location',
                                  paste0('  detects_', fig_count, ' <- detects_', fig_count, ' %>%'),
                                  paste0('               dplyr::left_join(., detects_', fig_count, ' %>%'),
                                  '                                   group_by(TagCode, general_location) %>%',
                                  '                                   summarise(last_detect = max(DateTime_PST))) %>%',
                                  '               mutate(Day = as.Date(last_detect, "Etc/GMT+8")) # Convert last detection to day',
                                  '',
                                  paste0('  starttime <- as.Date(min(detects_', fig_count, '$release_time), "Etc/GMT+8")'),
                                  '  ## Endtime should be either now or end of predicted tag life, whichever comes first',
                                  '  endtime <- min(as.Date(format(Sys.time(), "%Y-%m-%d")),',
                                  '             max(as.Date(detects_study$release_time)+(as.numeric(detects_study$tag_life))))',
                                  '',
                                  '  daterange <- data.frame(Date = seq.Date(from = starttime, to = endtime, by = "day"))',
                                  '',
                                  '  rels            <- unique(study_tagcodes$Release)',
                                  '  rel_num         <- length(rels)',
                                  paste0('  rels_no_detects <- as.character(rels[!(rels %in% unique(detects_', fig_count, '$Release))])'),
                                  '',
                                  paste0('  tagcount1 <- detects_', fig_count, ' %>%'),
                                  '              group_by(Day, general_location) %>%',
                                  '              summarise(unique_tags = length(unique(TagCode))) %>%',
                                  '              rename(., Date = Day, Location = general_location) %>%',
                                  '              mutate(Location = factor(Location, levels = c("Old_River_Quimby", "Holland_Cut_Quimby", "Old River",',
                                  '                                                            "MiddleRiver", "Clifton_Court_US_Radial_Gates",',
                                  '                                                            "SWP_radial_gates_DS", "SWP_radial_gates_US",',
                                  '                                                            "CVP_Trash_Rack_1", "CVP_Tank", "SWP_intake",',
                                  '                                                            "Clifton_Court_Intake_Canal")))',
                                  '',
                                  '  tagcount1 <- reshape2::dcast(tagcount, Date ~ Location, drop = FALSE)',
                                  '',
                                  '  daterange1 <- merge(daterange, tagcount1, all.x=T)',
                                  '  daterange1[is.na(daterange1)] <- 0',
                                  '  daterange2 <- daterange1',
                                  '  rownames(daterange2) <- daterange2$Date',
                                  '',
                                  '  par(mar=c(6, 5, 2, 5) + 0.1)',
                                  '',
                                  '  daterange3 <- melt(daterange2, id.vars = "Date", variable.name = ".", )',
                                  '',
                                  '  # Add latitude to daterange df',
                                  '  locs <- data.frame(general_location = unique(daterange3$.)) %>%',
                                  '          left_join(., recv_locs, by = "general_location") %>% filter(is.na(stop)) %>%',
                                  '          select(location, general_location, latitude) %>% group_by(general_location) %>%',
                                  '          summarise(latitude = mean(latitude))',
                                  '  locs <- locs[order(locs$latitude, decreasing = FALSE),]',
                                  '  locs$loc_num <- seq.int(nrow(locs))',
                                  '  daterange4 <- daterange3 %>% left_join(., locs, by = c("." = "general_location"))',
                                  '',
                                  '  # Get flow data from CDEC',
                                  '  flow <- cdec_query("OMR", "20", "H", starttime, endtime)',
                                  '',
                                  '  # Fish movement',
                                  paste0('  move_df <- detects_', fig_count, ' %>%'),
                                  '             distinct(., TagCode, last_detect, general_location,',
                                  '                      .keep_all = TRUE) # find last detection and remove duplicate value for that column',
                                  '  dup_codes   <- move_df$TagCode[which(duplicated(move_df$TagCode))] # then get the tag codes that were detected at multiple locations',
                                  '  move_df     <- move_df[(move_df$TagCode %in% dup_codes),] # save only the fish that were detected at multiple locations',
                                  '  move_df$Day <- as.Date(move_df$last_detect, "Etc/GMT+8")',
                                  '  new_move_df <- NULL',
                                  '  for(i in 1:length(unique(move_df$TagCode))){',
                                  '    tmp_code    <- unique(move_df$TagCode)[i]',
                                  '    tmp_move_df <- move_df %>% filter(TagCode == tmp_code) # subset data',
                                  '    tmp_move_df <- tmp_move_df[order(tmp_move_df$last_detect, decreasing = FALSE),] # order data',
                                  '    for(j in 1:(length(tmp_move_df$TagCode) - 1)){',
                                  '      tmp_new_move_df <- data.frame(TagCode = tmp_code, location1 = tmp_move_df$general_location[j],',
                                  '                                   day1 = tmp_move_df$Day[j], location2 = tmp_move_df$general_location[j+1],',
                                  '                                   day2 = tmp_move_df$Day[j+1])',
                                  '      tmp_new_move_df$loc_num1 <- locs$loc_num[which(locs$general_location == tmp_new_move_df$location1)]',
                                  '      tmp_new_move_df$loc_num2 <- locs$loc_num[which(locs$general_location == tmp_new_move_df$location2)]',
                                  '      new_move_df <- rbind(new_move_df, tmp_new_move_df)',
                                  '    }',
                                  '  }',
                                  '',
                                  '  fig1 <- plot_ly(data = daterange4, type = "scatter", mode = "markers", ',
                                  '                  marker = list(color = ~ value, size = ~value*5, ',
                                  '                                colorbar = list(title = "Num. of arrivals", len = 0.35, x = 1.06, y = 0.73), ',
                                  '                                colorscale = "Viridis", line = list(width = 0)),',
                                  '                   hoverinfo = "text", text = ~paste("Date:", Date,"<br># of arrivals:", value),',
                                  '                   x = ~Date, y = ~loc_num) %>%',
                                  '          add_annotations(x = new_move_df$day2, y = new_move_df$loc_num2, axref="x", ayref="y", text="", showarrow=TRUE,',
                                  '                          ax = new_move_df$day1, ay = new_move_df$loc_num1, arrowcolor = "darkgrey",',
                                  '                          opacity = 0.5, standoff = 5, startstandoff = 5) %>%',
                                  '          layout(xaxis = list(range = c(min(daterange$Date) - 1, max(daterange$Date) + 1), showgrid = FALSE, showline = TRUE),',
                                  '                 yaxis = list(range = c(min(locs$loc_num) - 1, max(locs$loc_num) + 1), showline = TRUE,',
                                  '                 title = "", ticktext = locs$general_location, tickvals = locs$loc_num), showlegend = FALSE) %>% ',
                                  '          add_annotations(text = sprintf("<b>North<b>"), xref = "paper", yref = "paper", x = -0.13, xanchor = "left",',
                                  '                          y = 1.05, yanchor = "top", showarrow = FALSE, font = list(size = 20)) %>%',
                                  '          add_annotations(text = sprintf("<b>South<b>"), xref = "paper", yref = "paper", x = -0.13, xanchor = "left",',
                                  '                          y = 0.04, yanchor = "top", showarrow = FALSE, font = list(size = 20))',
                                  '',
                                  '  fig2 <- plot_ly(data = flow, type = "scatter", mode = "lines") %>%',
                                  '          add_trace(x = ~datetime, y = ~parameter_value) %>%',
                                  '          layout(xaxis = list(range = c(min(daterange$Date) - 1, max(daterange$Date) + 1), showgrid = FALSE, showline = TRUE),',
                                  '                 yaxis = list(title = "Flow (cfs) at OMR"))',
                                  '',
                                  '  subplot(fig1, fig2, nrows = 2, margin = 0.04, heights = c(0.7, 0.3), titleY = TRUE)',
                                  '',
                                  '} else {',
                                  '  plot(1:2, type = "n", xlab = "",xaxt = "n", yaxt = "n", ylab = "Number of fish arrivals per day")',
                                  '  text(1.5,1.5, labels = "NO DETECTIONS YET", cex = 2)',
                                  '}',
                                  '',
                                  '```',
                                  '',
                                  '<br/>',
                                  '',
                                  sep = "\n")
      
      detection_figs <- paste(detection_figs,
                              detection_figs_tmp,
                              sep = "\n")
   }
   
   # Benicia Bridge
   if(release_region >= 1 & release_region <= 5){
      fig_count <- fig_count + 1
      detection_figs_tmp <- paste(paste0('```{r print figure of fish detections at ', 'Benicia Bridge', ', message = FALSE, warning=F, fig.height = 6, fig.width = 10, out.extra=',"'style=",
                                         '"background-color: #000000; padding:3px"',"', fig.cap=",
                                         '"2.',fig_count,' ', 'Detections at Benicia Bridge for duration of tag life','"}'),
                                  '',
                                  'library(tidyr)',
                                  '',
                                  paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
                                  '',
                                  paste0('detects_', fig_count, ' <- detects_study %>% filter(general_location == "Benicia_west" | general_location == "Benicia_east")'),
                                  '',
                                  paste0('if(nrow(detects_', fig_count,') == 0){'),
                                  '   plot(1:2, type = "n", xlab = "",xaxt = "n", yaxt = "n", ylab = "Number of fish arrivals per day")',
                                  '   text(1.5,1.5, labels = "NO DETECTIONS YET", cex = 2)',
                                  '} else {',
                                  paste0('  detects_', fig_count, ' <- detects_', fig_count, ' %>%'),
                                  paste0('    dplyr::left_join(., detects_', fig_count, ' %>%'),
                                  '                        group_by(TagCode) %>% ',
                                  '                        summarise(first_detect = min(DateTime_PST))) %>%',
                                  '                        mutate(Day = as.Date(as.Date(first_detect, "Etc/GMT+8")))',
                                  '',
                                  paste0('  starttime <- as.Date(min(detects_', fig_count, '$release_time), "Etc/GMT+8")'),
                                  '',
                                  '  # Endtime should be either now, or end of predicted tag life, whichever comes first',
                                  '  endtime <- min(as.Date(format(Sys.time(), "%Y-%m-%d")),',
                                  '                 max(as.Date(detects_study$release_time)+(as.numeric(detects_study$tag_life))))',
                                  '',
                                  '  daterange <- data.frame(Day = seq.Date(from = starttime, to = endtime, by = "day"))',
                                  '',
                                  '  rels            <- unique(study_tagcodes$Release)',
                                  '  rel_num         <- length(rels)',
                                  paste0('  rels_no_detects <- as.character(rels[!(rels %in% unique(detects_', fig_count, '$Release))])'),
                                  '',
                                  paste0('  tagcount1 <- detects_', fig_count, ' %>%'),
                                  '               group_by(Day, Release) %>%',
                                  '               summarise(unique_tags = length(unique(TagCode))) %>%',
                                  '               spread(Release, unique_tags)',
                                  '',
                                  '  daterange1 <- merge(daterange, tagcount1, all.x=T)',
                                  '  daterange1[is.na(daterange1)] <- 0',
                                  '',
                                  '  if(length(rels_no_detects)>0){',
                                  '    for(i in rels_no_detects){',
                                  '      daterange1 <- cbind(daterange1, x=NA)',
                                  '      names(daterange1)[names(daterange1) == "x"] <- paste(i)',
                                  '    }',
                                  '  }',
                                  '',
                                  '  ## reorder columns in alphabetical order so its coloring in barplots is consistent',
                                  '  daterange1 <- daterange1[,order(colnames(daterange1))]',
                                  '  daterange2 <- daterange1',
                                  '  rownames(daterange2) <- daterange2$Day',
                                  '  daterange2$Day <- NULL',
                                  '',
                                  '  par(mar=c(6, 5, 2, 5) + 0.1)',
                                  '',
                                  '  daterange2$Date <- as.Date(row.names(daterange2))',
                                  '  daterange3      <- melt(daterange2, id.vars = "Date", variable.name = ".", )',
                                  '  daterange3$.    <- factor(daterange3$., levels = sort(unique(daterange3$.), decreasing = T))',
                                  '',
                                  '  plot_ly(daterange3, width = 900, height = 600, dynamicTicks = TRUE) %>%',
                                  '    add_bars(x = ~Date, y = ~value, color = ~.) %>%',
                                  '    add_annotations( text="Release (click on legend items to isolate)", xref="paper", yref="paper",',
                                  '                     x=0.01, xanchor="left",',
                                  '                     y=1.056, yanchor="top",    # Same y as legend below',
                                  '                     legendtitle=TRUE, showarrow=FALSE ) %>%',
                                  '    layout(showlegend = T, ',
                                  '           barmode = "stack",',
                                  '           xaxis = list(title = "Date", mirror=T,ticks="outside",showline=T), ',
                                  '           yaxis = list(title = "Number of fish arrivals per day", mirror=T,ticks="outside",showline=T),',
                                  '           legend = list(orientation = "h",x = 0.34, y = 1.066),',
                                  '           margin=list(l = 50,r = 100,b = 50,t = 50))',
                                  '}',
                                  '```',
                                  '',
                                  '<br/>',
                                  '',
                                  sep = "\n")
      
      detection_figs <- paste(detection_figs,
                              detection_figs_tmp,
                              sep = "\n")
   }
   
   return(detection_figs)
}

# Create survival and routing probability
create_survival_tables <- function(release_region, georgiana){
   surv_tables <- paste('***',
                        '## _3. Survival and Routing Probability_',
                        '***',
                        '',
                        sep = "\n")
   
   table_count <- 0
   
   # Tower Bridge
   if(release_region >= 1 | release_region <= 3){
      table_count <- table_count + 1
      surv_tables_tmp <- paste('```{r print table of survival to Tower, message = FALSE, results= "asis", warning=FALSE}',
                               '',
                               paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
                               '',
                               'detects_tower <- detects_study %>% filter(general_location == "TowerBridge")',
                               '',
                               'if(nrow(detects_tower) == 0){',
                               '  WR.surv <- data.frame("Release"=NA, "Survival (%)"="NO DETECTIONS YET", "SE"=NA, "95% lower C.I."=NA,',
                               '                        "95% upper C.I."=NA, "Detection efficiency (%)"=NA)',
                               '  colnames(WR.surv) <- c("Release", "Survival (%)", "SE", "95% lower C.I.",',
                               '                         "95% upper C.I.", "Detection efficiency (%)")',
                               paste0('  print(kable(WR.surv, row.names = F, "html", caption = "3.', table_count, ' Minimum survival to Tower Bridge (using CJS'),
                               '              survival model). If Yolo Bypass Weirs are overtopping during migration, fish may have taken',
                               '              that route, and therefore this is a minimum estimate of survival") %>%',
                               '    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"),',
                               '                  full_width = F, position = "left"))',
                               '',
                               '} else {',
                               '',
                               '  study_count <- nrow(study_tagcodes)',
                               '',
                               '  # Only do survival to Sac for now',
                               '  surv <- detects_study %>% filter(river_km > 168 & river_km < 175)',
                               '',
                               '  # Create inp for survival estimation',
                               '  inp <- as.data.frame(reshape2::dcast(surv, TagCode ~ river_km, fun.aggregate = length))',
                               '',
                               '  # Sort columns by river km in descending order',
                               '  gen_loc_sites <- ncol(inp)-1 # Count number of genlocs',
                               '  if(gen_loc_sites < 2){',
                               '    WR.surv <- data.frame("Release"=NA, "Survival (%)"="NOT ENOUGH DETECTIONS", "SE"=NA, "95% lower C.I."=NA,',
                               '                          "95% upper C.I."=NA, "Detection efficiency (%)"=NA)',
                               '    colnames(WR.surv) <- c("Release", "Survival (%)", "SE", "95% lower C.I.", "95% upper C.I.",',
                               '                           "Detection efficiency (%)")',
                               paste0('    print(kable(WR.surv, row.names = F, "html", caption = "3.', table_count, ' Minimum survival to Tower Bridge (using CJS'),
                               '                survival model). If Yolo Bypass Weirs are overtopping during migration, fish may',
                               '                have taken that route, and therefore this is a minimum estimate of survival") %>%',
                               '      kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), ',
                               '                    full_width = F,position = "left"))',
                               '  } else {',
                               '    inp <- inp[,c(1,order(names(inp[,2:(gen_loc_sites+1)]), decreasing = T)+1)] %>%',
                               '           dplyr::left_join(study_tagcodes, ., by = "TagCode")',
                               '',
                               '    inp2 <- inp[,(ncol(inp)-gen_loc_sites+1):ncol(inp)] %>%',
                               '            replace(is.na(.), 0) %>%',
                               '            replace(., . > 0, 1)',
                               '',
                               '    inp          <- cbind(inp, inp2)',
                               '    groups       <- as.character(sort(unique(inp$Release)))',
                               '    surv$Release <- factor(surv$Release, levels = groups)',
                               '    inp[,groups] <- 0',
                               '',
                               '    for (i in groups) {',
                               '      inp[as.character(inp$Release) == i, i] <- 1',
                               '    }',
                               '',
                               '    inp$inp_final <- paste("1",apply(inp2, 1, paste, collapse=""),sep="")',
                               '',
                               '    if(length(groups) > 1){',
                               '      # make sure factor levels have a release that has detections first. if first release in factor order',
                               '      # has zero detectins, model goes haywire',
                               '      inp.df <- data.frame(ch = as.character(inp$inp_final), freq = 1,',
                               '                           rel = factor(inp$Release, levels = names(sort(table(surv$Release),decreasing = T))),',
                               '                           stringsAsFactors = F)',
                               '',
                               '      WR.process <- process.data(inp.df, model="CJS", begin.time=1, groups = "rel")     ',
                               '',
                               '      WR.ddl <- make.design.data(WR.process)',
                               '',
                               '      WR.mark.all <- mark(WR.process, WR.ddl,',
                               '                          model.parameters=list(Phi=list(formula=~time),p=list(formula=~time)), ',
                               '                          silent = T, output = F)',
                               '',
                               '      WR.mark.rel <- mark(WR.process, WR.ddl,',
                               '                          model.parameters=list(Phi=list(formula=~time*rel),p=list(formula=~time)),',
                               '                          silent = T, output = F)',
                               '',
                               '      WR.surv <- round(WR.mark.all$results$real[1,c("estimate", "se", "lcl", "ucl")] * 100,1)',
                               '      WR.surv <- rbind(WR.surv, round(WR.mark.rel$results$real[seq(from=1,to=length(groups)*2,by = 2),',
                               '                                                               c("estimate", "se", "lcl", "ucl")] * 100,1))',
                               '      WR.surv$Detection_efficiency <- NA',
                               '      WR.surv[1,"Detection_efficiency"] <- round(WR.mark.all$results$real[gen_loc_sites+1,"estimate"] * 100,1)',
                               '      WR.surv <- cbind(c("ALL", names(sort(table(surv$Release),decreasing = T))), WR.surv)',
                               '    }',
                               '    if(length(intersect(colnames(inp),groups)) < 2){',
                               '      inp$inp_final <- paste("1",apply(inp2, 1, paste, collapse=""), " ", 1,sep = "")',
                               '      write.table(inp$inp_final,"WRinp.inp",row.names = F, col.names = F, quote = F)',
                               '      WRinp <- convert.inp("WRinp.inp")',
                               '      WR.process <- process.data(WRinp, model="CJS", begin.time=1)',
                               '',
                               '      WR.ddl <- make.design.data(WR.process)',
                               '',
                               '      WR.mark.all <- mark(WR.process, WR.ddl,',
                               '                          model.parameters=list(Phi=list(formula=~time),p=list(formula=~time)), ',
                               '                          silent = T, output = F)',
                               '',
                               '      WR.mark.rel <- mark(WR.process, WR.ddl,',
                               '                          model.parameters=list(Phi=list(formula=~time),p=list(formula=~time)), ',
                               '                          silent = T, output = F)',
                               '',
                               '      WR.surv <- round(WR.mark.all$results$real[1,c("estimate", "se", "lcl", "ucl")] * 100,1)',
                               '      WR.surv <- rbind(WR.surv, round(WR.mark.rel$results$real[seq(from=1,to=length(groups)*2,by = 2),',
                               '                                                               c("estimate", "se", "lcl", "ucl")] * 100,1))',
                               '      WR.surv$Detection_efficiency <- NA',
                               '      WR.surv[1,"Detection_efficiency"] <- round(WR.mark.all$results$real[gen_loc_sites+1,"estimate"] * 100,1)',
                               '      WR.surv <- cbind(c("ALL", groups), WR.surv)',
                               '    }',
                               '',
                               '    colnames(WR.surv) <- c("Release", "Survival (%)", "SE", "95% lower C.I.", ',
                               '                           "95% upper C.I.", "Detection efficiency (%)")',
                               '',
                               paste0('    print(kable(WR.surv, row.names = F, "html", caption = "3.', table_count, ' Minimum survival to Tower Bridge (using CJS'),
                               '                survival model). If Yolo Bypass Weirs are overtopping during migration, fish may have taken ',
                               '                that route, and therefore this is a minimum estimate of survival") %>%',
                               '            kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), ',
                               '                          full_width = F, position = "left"))',
                               '  }',
                               '}',
                               '```',
                               '',
                               '<br/>',
                               '',
                               sep = "\n")
      
      surv_tables <- paste(surv_tables,
                           surv_tables_tmp,
                           sep = "\n")
   }
   
   # Georgiana Slough
   if((release_region >= 1 & release_region <= 3) & georgiana == TRUE){
      table_count <- table_count + 1
      surv_tables_tmp <- paste('```{r print table of survival and routing to Georgiana Slough, message = FALSE, results= "asis", warning=FALSE}',
                               '',
                               paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
                               '',
                               'route_results_possible <- FALSE',
                               '',
                               'if(nrow(detects_study[is.na(detects_study$DateTime_PST)==F,]) == 0){',
                               '  results_short <- data.frame("Measure"=NA, "Estimate"="NO DETECTIONS YET", "SE"=NA, "95% lower C.I."=NA,',
                               '                              "95% upper C.I."=NA)',
                               '  colnames(results_short) <- c("Measure", "Estimate", "SE", "95% lower C.I.", "95% upper C.I.")',
                               paste0('  print(kable(results_short, row.names = F, "html", caption = "3.', table_count, ' Reach-specific survival and probability'),
                               '                                                               of entering Georgiana Slough") %>%',
                               '          kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"),',
                               '                        full_width = F, position = "left"))',
                               '} else {',
                               '',
                               '  # Only do survival to Georg split for now',
                               '  test2 <- detects_study %>%',
                               '           filter(general_location %in% c("ButteBrRT","TowerBridge", "I80-50_Br", "Sac_BlwGeorgiana",',
                               '                                          "Sac_BlwGeorgiana2", "Georgiana_Slough1", "Georgiana_Slough2"))',
                               '',
                               '  # We can only do a multi-state model if there is at least one detection in each route',
                               '  if(nrow(test2[test2$general_location %in% c("Sac_BlwGeorgiana", "Sac_BlwGeorgiana2"),]) == 0 |',
                               '     nrow(test2[test2$general_location %in% c("Georgiana_Slough1", "Georgiana_Slough2"),]) == 0){',
                               '    results_short <- data.frame("Measure"=NA, "Estimate"="NOT ENOUGH DETECTIONS", "SE"=NA, "95% lower C.I."=NA,',
                               '                                "95% upper C.I."=NA)',
                               '    colnames(results_short) <- c("Measure", "Estimate", "SE", "95% lower C.I.", "95% upper C.I.")',
                               paste0('    print(kable(results_short, row.names = F, "html", caption = "3.', table_count, ' Reach-specific survival and probability of'),
                               '                entering Georgiana Slough") %>%',
                               '            kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"),',
                               '                          full_width = F, position = "left"))',
                               '  } else {',
                               '',
                               '    # Make tagcode character',
                               '    study_tagcodes$TagCode <- as.character(study_tagcodes$TagCode)',
                               '',
                               '    # Make a crosstab query with frequencies for all tag/location combination',
                               '    test2$general_location <- factor(test2$general_location,',
                               '                                     levels = c("ButteBrRT","TowerBridge", "I80-50_Br", "Sac_BlwGeorgiana",',
                               '                                                "Sac_BlwGeorgiana2", "Georgiana_Slough1", "Georgiana_Slough2"))',
                               '    test2$TagCode <- factor(test2$TagCode, levels = study_tagcodes$TagCode)',
                               '    mytable <- table(test2$TagCode, test2$general_location) # A will be rows, B will be columns',
                               '',
                               '    # Change all frequencies bigger than 1 to 1. Here you could change your minimum cutoff to 2 detections,',
                               '    # and then make another command that changes all detections=1 to 0',
                               '    mytable[mytable>0] <- "A"',
                               '',
                               '    # Order in order of rkm',
                               '    mytable2 <- mytable[, c("ButteBrRT","TowerBridge", "I80-50_Br", "Sac_BlwGeorgiana", "Sac_BlwGeorgiana2",',
                               '                            "Georgiana_Slough1", "Georgiana_Slough2")]',
                               '',
                               '    # Now sort the crosstab rows alphabetically',
                               '    mytable2 <- mytable2[order(row.names(mytable2)),]',
                               '    mytable2[which(mytable2[, "Sac_BlwGeorgiana"]=="A"), "Sac_BlwGeorgiana"]   <- "A"',
                               '    mytable2[which(mytable2[, "Sac_BlwGeorgiana2"]=="A"), "Sac_BlwGeorgiana2"] <- "A"',
                               '    mytable2[which(mytable2[, "Georgiana_Slough1"]=="A"), "Georgiana_Slough1"] <- "B"',
                               '    mytable2[which(mytable2[, "Georgiana_Slough2"]=="A"), "Georgiana_Slough2"] <- "B"',
                               '',
                               '    # Now order the study_tagcodes table the same way',
                               '    study_tagcodes <- study_tagcodes[order(study_tagcodes$TagCode),]',
                               '',
                               '    # Paste together (concatenate) the data from each column of the crosstab into one string per row, add to tagging_meta.',
                               '    # For this step, make sure both are sorted by FishID',
                               '    study_tagcodes$inp_part1 <- apply(mytable2[,1:3],1,paste,collapse="")',
                               '    study_tagcodes$inp_partA <- apply(mytable2[,4:5],1,paste,collapse="")',
                               '    study_tagcodes$inp_partB <- apply(mytable2[,6:7],1,paste,collapse="")',
                               '',
                               '    # find last detection at each genloc',
                               '    departure <- aggregate(list(depart = test2$DateTime_PST), by = list(TagCode = test2$TagCode, last_location = test2$general_location), FUN = max)',
                               '    # subset for just juncture locations',
                               '    departure <- departure[departure$last_location %in% c("Sac_BlwGeorgiana", "Sac_BlwGeorgiana2", "Georgiana_Slough1", "Georgiana_Slough2"),]',
                               '    # Find genloc of last known detection per tag',
                               '    last_depart    <- aggregate(list(depart = departure$depart), by = list(TagCode = departure$TagCode), FUN = max)',
                               '    last_depart1   <- merge(last_depart, departure)',
                               '    study_tagcodes <- merge(study_tagcodes, last_depart1[,c("TagCode", "last_location")], by = "TagCode", all.x = T)',
                               '',
                               '    # Assume that the Sac is default pathway, and for fish that were detected in neither route, it would get a "00" in inp so does not matter anyway',
                               '    study_tagcodes$inp_final <- paste("A",study_tagcodes$inp_part1, study_tagcodes$inp_partA," 1 ;", sep = "")',
                               '',
                               '    # now put in exceptions...fish that were seen in georgiana last',
                               '    study_tagcodes[study_tagcodes$last_location %in% c("Georgiana_Slough1", "Georgiana_Slough2"), "inp_final"] <-',
                               '       paste("A",',
                               '             study_tagcodes[study_tagcodes$last_location %in% c("Georgiana_Slough1", "Georgiana_Slough2"), "inp_part1"],',
                               '             study_tagcodes[study_tagcodes$last_location %in% c("Georgiana_Slough1", "Georgiana_Slough2"), "inp_partB"],',
                               '             " 1 ;", ',
                               '             sep = "")',
                               '',
                               '    # At this point, some fish might not have been deemed to ever take a route based on last visit analysis. If so, model cannot be run',
                               '    if(any(grepl(pattern = "A", study_tagcodes$inp_final)==T) & any(grepl(pattern = "B", study_tagcodes$inp_final)==T)){',
                               '',
                               '      write.table(study_tagcodes$inp_final,"WRinp_multistate.inp",row.names = F, col.names = F, quote = F)',
                               '',
                               '      WRinp <- convert.inp("WRinp_multistate.inp")',
                               '',
                               '      dp <- process.data(WRinp, model="Multistrata") ',
                               '',
                               '      ddl <- make.design.data(dp)',
                               '',
                               '      #### p ####',
                               '      # Cannott be seen at 2B or 3B or 4B (butte, tower or I80)',
                               '      ddl$p$fix = NA',
                               '      ddl$p$fix[ddl$p$stratum == "B" & ddl$p$time %in% c(2,3,4)] = 0',
                               '',
                               '      #### Psi ####',
                               '      # Only 1 transition allowed:',
                               '      # from A to B at time interval 4 to 5',
                               '      ddl$Psi$fix = 0',
                               '      # A to B can only happen for interval 3-4',
                               '      ddl$Psi$fix[ddl$Psi$stratum == "A"&',
                               '                  ddl$Psi$tostratum == "B" & ',
                               '                  ddl$Psi$time == 4] = NA',
                               '',
                               '      #### Phi a.k.a. S ####',
                               '      ddl$S$fix = NA',
                               '      # None in B for reaches 1,2,3,4 and fixing it to 1 for 5 (between two georg lines). All getting fixed to 1',
                               '      ddl$S$fix[ddl$S$stratum == "B" & ddl$S$time %in% c(1,2,3,4,5)] = 1',
                               '',
                               '      # For route A, fixing it to 1 for 5 (between two blw_georg lines)',
                               '      ddl$S$fix[ddl$S$stratum == "A" & ddl$S$time == 5] = 1',
                               '      # We use -1 at beginning of formula to remove intercept. This is because different routes probably should not share the same intercept',
                               '',
                               '      p.timexstratum   = list(formula=~-1+stratum:time)',
                               '      Psi.stratumxtime = list(formula=~-1+stratum:time)',
                               '      S.stratumxtime   = list(formula=~-1+stratum:time)',
                               '',
                               '      # Run model a first time',
                               '      S.timexstratum.p.timexstratum.Psi.timexstratum = mark(dp, ddl,',
                               '                                                            model.parameters = list(S = S.stratumxtime,p = p.timexstratum,Psi = Psi.stratumxtime),',
                               '                                                            realvcv = T, silent = T, output = F)',
                               '',
                               '      # Identify any parameter estimates at 1, which would likely have bad SE estimates.',
                               '      profile.intervals <- which(S.timexstratum.p.timexstratum.Psi.timexstratum$results$real$estimate %in% c(0,1) &',
                               '                                 !S.timexstratum.p.timexstratum.Psi.timexstratum$results$real$fixed == "Fixed")',
                               '',
                               '      # Rerun model using profile interval estimation for the tricky parameters',
                               '      S.timexstratum.p.timexstratum.Psi.timexstratum = mark(dp, ddl,',
                               '                                                            model.parameters=list(S=S.stratumxtime,p= p.timexstratum,Psi=Psi.stratumxtime),',
                               '                                                            realvcv = T, profile.int = profile.intervals, silent = T, output = F)',
                               '',
                               '      results <- S.timexstratum.p.timexstratum.Psi.timexstratum$results$real',
                               '',
                               '      results_short <- results[rownames(results) %in% c("S sA g1 c1 a0 o1 t1",',
                               '                                                        "S sA g1 c1 a1 o2 t2",',
                               '                                                        "S sA g1 c1 a2 o3 t3",',
                               '                                                        "S sA g1 c1 a3 o4 t4",',
                               '                                                        "p sA g1 c1 a1 o1 t2",',
                               '                                                        "p sA g1 c1 a2 o2 t3",',
                               '                                                        "p sA g1 c1 a3 o3 t4",',
                               '                                                        "p sA g1 c1 a4 o4 t5",',
                               '                                                        "p sB g1 c1 a4 o4 t5",',
                               '                                                        "Psi sA toB g1 c1 a3 o4 t4"),]',
                               '',
                               '      results_short <- round(results_short[,c("estimate", "se", "lcl", "ucl")] * 100,1)',
                               '',
                               '      # Now find estimate and CIs for AtoA route at junction',
                               '      Psilist   = get.real(S.timexstratum.p.timexstratum.Psi.timexstratum,"Psi",vcv=TRUE)',
                               '      Psivalues = Psilist$estimates',
                               '',
                               '      routes <- TransitionMatrix(Psivalues[Psivalues$time==4 & Psivalues$cohort==1,],vcv.real=Psilist$vcv.real)',
                               '',
                               '      results_short$Measure <- c("Survival from release to Butte City","Survival from Butte City to TowerBridge (minimum estimate since fish may have taken Yolo',
                               '                                 Bypass)", "Survival from TowerBridge to I80-50_Br", "% arrived from I80-50_Br to Georgiana Slough confluence (not survival because',
                               '                                 fish may have taken Sutter/Steam)","Detection probability at Butte City",',
                               '                                 "Detection probability at TowerBridge", "Detection probability at I80-50_Br", "Detection probability at Blw_Georgiana", ',
                               '                                 "Detection probability at Georgiana Slough",',
                               '                                 "Routing probability into Georgiana Slough (Conditional on fish arriving to junction)")',
                               '',
                               '      results_short <- results_short[,c("Measure", "estimate", "se", "lcl", "ucl")]',
                               '      colnames(results_short) <- c("Measure", "Estimate", "SE", "95% lower C.I.", "95% upper C.I.")',
                               '',
                               paste0('      print(kable(results_short, row.names = F, "html", caption = "3.', table_count, ' Reach-specific survival and probability of entering Georgiana Slough") %>%'),
                               '              kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
                               '',
                               '      route_results_possible <- TRUE',
                               '',
                               '    } else {',
                               '      results_short <- data.frame("Measure"=NA, "Estimate"="NOT ENOUGH DETECTIONS YET", "SE"=NA, "95% lower C.I."=NA, "95% upper C.I."=NA)',
                               '      colnames(results_short) <- c("Measure", "Estimate", "SE", "95% lower C.I.", "95% upper C.I.")',
                               paste0('      print(kable(results_short, row.names = F, "html", caption = "3.', table_count, ' Reach-specific survival and probability of entering Georgiana Slough") %>%'),
                               '              kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
                               '    }',
                               '  }',
                               '}',
                               '```',
                               '',
                               '```{r figure of routing with pic, fig.align="left", fig.height = 7, fig.width = 7.6}',
                               '# If you do not have access to local files, uncomment and run next lines of code',
                               '#download.file("https://raw.githubusercontent.com/CalFishTrack/real-time/master/data/georg.png",destfile = "georg.png", quiet = T, mode = "wb")',
                               '',
                               'georg <- readPNG("georg.png")',
                               'par(mar = c(2,0,0,0))',
                               '# Set up the plot area',
                               'plot(1:2, type="n", xlab="", ylab="", xaxt = "n", yaxt = "n")',
                               '',
                               '# Get the plot information so the image will fill the plot box, and draw it',
                               'lim <- par()',
                               'rasterImage(georg, lim$usr[1], lim$usr[3], lim$usr[2], lim$usr[4])',
                               'if(nrow(detects_study[is.na(detects_study$DateTime_PST) == F,]) == 0){',
                               '    legend(x = 1.55,y = 1.6,legend =  "No detections yet",col = "white", box.col = "light gray", bg = "light gray") ',
                               '    legend(x = 1.55,y = 1.45,legend =  "No detections yet",col = "white", box.col = "light gray", bg = "light gray")',
                               '',
                               '} else if (route_results_possible == F){',
                               '    legend(x = 1.55,y = 1.6,legend =  "Too few detections",col = "white", box.col = "light gray", bg = "light gray") ',
                               '    legend(x = 1.55,y = 1.45,legend =  "Too few detections",col = "white", box.col = "light gray", bg = "light gray")',
                               '',
                               '} else {',
                               '  legend(x = 1.55,y = 1.6,legend =  paste(round(routes$TransitionMat["A","A"],3)*100,',
                               '                                          "% (", round(routes$lcl.TransitionMat["A","A"],3)*100, "-",',
                               '                                          round(routes$ucl.TransitionMat["A","A"],3)*100,")", sep =""),',
                               '         col = "white", box.col = "light gray", bg = "light gray")',
                               '  legend(1.55,1.45, legend =  paste(round(routes$TransitionMat["A","B"],3)*100, ',
                               '                                    "% (", round(routes$lcl.TransitionMat["A","B"],3)*100, "-",',
                               '                                    round(routes$ucl.TransitionMat["A","B"],3)*100,")", sep =""),',
                               '         box.col = "light gray", bg = "light gray")',
                               '}',
                               '',
                               paste0('mtext(text = "3.', (table_count + 1), ' Routing Probabilities at Georgiana Slough Junction (with 95% C.I.s)", cex = 1.3, side = 1, line = 0.2, adj = 0)'),
                               '```',
                               '',
                               paste0('```{r compare STARs to empirical routing estimate, fig.align="left", fig.height = 7, ',
                                      'fig.width = 7.6, out.extra="style="background-color: #000000; padding:3px"",  fig.cap = "3.',
                                      table_count + 2,
                                      ' STARS prediction vs. empirical estimate of Routing Probability at Georgiana Slough Junction", warning=F, message=F}'),
                               '',
                               'if (nrow(detects_study[is.na(detects_study$DateTime_PST)==F,]) == 0){',
                               '  plot(1:2, type = "n",xaxt = "n", yaxt = "n",',
                               '       xlab = "Range of days study fish were present at Georgiana Sl Junction",',
                               '       ylab = "Routing probability into Georgiana Slough at the junction")',
                               '  text(1.5,1.5, labels = "NO DETECTIONS YET", cex = 2)',
                               '',
                               '} else if(route_results_possible == F){',
                               '  plot(1:2, type = "n",xaxt = "n", yaxt = "n",',
                               '       xlab = "Range of days study fish were present at Georgiana Sl Junction",',
                               '       ylab = "Routing probability into Georgiana Slough at the junction")',
                               '  text(1.5,1.5, labels = "TOO FEW DETECTIONS", cex = 2)',
                               '',
                               '} else {',
                               '  library(repmis)',
                               '  trytest <- try(source_data("https://code.usgs.gov/crrl_qfes/Enhanced_Acoustic_Telemetry_Project/raw/master/EAT_data_2021.Rdata?raw=True"))',
                               '',
                               '  if (inherits(trytest, "try-error")){',
                               '    plot(1:2, type = "n",xaxt = "n", yaxt = "n",',
                               '         xlab = "Range of days study fish were present at Georgiana Sl Junction",',
                               '         ylab = "Routing probability into Georgiana Slough at the junction")',
                               '    text(1.5,1.5, labels = "ERROR DOWNLOADING STARS", cex = 2)',
                               '',
                               '  } else {',
                               '    # first, find min and max arrivals at georg for a study',
                               '    min_georg <- as.Date(format(min(test2[test2$general_location %in% c("Sac_BlwGeorgiana", "Sac_BlwGeorgiana2","Georgiana_Slough1",',
                               '                                                                        "Georgiana_Slough2"),"DateTime_PST"]), "%Y-%m-%d"))',
                               '    max_georg <- as.Date(format(max(test2[test2$general_location %in% c("Sac_BlwGeorgiana", "Sac_BlwGeorgiana2","Georgiana_Slough1",',
                               '                                                                        "Georgiana_Slough2"),"DateTime_PST"]), "%Y-%m-%d"))',
                               '',
                               '    psi_study <- psi_GeoCond[psi_GeoCond$Date <= max_georg & psi_GeoCond$Date >=min_georg-1,]',
                               '',
                               '    plot(psi_study$Date, psi_study$psi_geo.50, ylim = c(0,1), xlim = c(min_georg, max_georg), type = "n", xaxt = "n",',
                               '         xlab = "Range of days study fish were present at Georgiana Sl Junction",',
                               '         ylab = "Routing probability into Georgiana Slough at the junction")',
                               '    polygon(c(psi_study$Date, rev(psi_study$Date)),',
                               '            c(psi_study$psi_geo.10,rev(psi_study$psi_geo.90)), density = 200, col ="grey90")',
                               '    lines(psi_study$Date, psi_study$psi_geo.50, lty = 3)',
                               '    points(mean(psi_study$Date), tail(results_short$Estimate,1)/100, pch = 16, cex = 1.3)',
                               '    arrows(mean(psi_study$Date), tail(results_short$`95% lower C.I.`,1)/100,',
                               '           mean(psi_study$Date), tail(results_short$`95% upper C.I.`,1)/100, length=0.05, angle=90, code=3)',
                               '    axis(side=1, at=psi_study$Date, labels=format(psi_study$Date, "%b-%d"))',
                               '    legend("topright", legend = c("STARS daily predictions during study (w/ 90% CI)", "Empirical estimate over study period (w/ 95% CI)"),',
                               '           bty     = "n",',
                               '           col     = c("black","black"),',
                               '           lty     = c(3,1),',
                               '           fill    = c("grey90", NA),',
                               '           border  = c(NA,NA),',
                               '           pch     = c(NA,16),',
                               '           seg.len = 0.8,',
                               '           cex     = 1.2',
                               '    )',
                               '  }',
                               '}',
                               '```',
                               '',
                               '<br/>',
                               '',
                               sep = "\n")
      
      table_count <- table_count + 2
      
      surv_tables <- paste(surv_tables,
                           surv_tables_tmp,
                           sep = "\n")
   }
   
   # Delta survival
   if(release_region >= 1 & release_region <= 4){
      table_count <- table_count + 1
      surv_tables_tmp <- paste('```{r print table of through-Delta survival, message = FALSE, results= "asis", warning=FALSE}',
                               '',
                               paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
                               '',
                               'try(Delta <- read.csv("Delta_surv.csv", stringsAsFactors = F))',
                               '',
                               'if(nrow(detects_study[is.na(detects_study$DateTime_PST) == F,]) == 0){',
                               '    WR.surv1 <- data.frame("Measure"=NA, "Estimate"="NO DETECTIONS YET", "SE"=NA, "95% lower C.I."=NA, "95% upper C.I."=NA)',
                               '    colnames(WR.surv1) <- c("Measure", "Estimate", "SE", "95% lower C.I.", "95% upper C.I.")',
                               paste0('    print(kable(WR.surv1, row.names = F, "html", caption = "3.', table_count, ' Minimum through-Delta survival: City of Sacramento to Benicia (using CJS survival model)") %>%'),
                               '            kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
                               '',
                               '} else {',
                               '  test4 <- detects_study[detects_study$general_location %in% c("TowerBridge", "I80-50_Br", "Benicia_west", "Benicia_east"),]',
                               '',
                               '  if(nrow(test4[test4$general_location =="Benicia_west",]) == 0 | nrow(test4[test4$general_location =="Benicia_east",]) == 0){',
                               '    WR.surv1 <- data.frame("Measure"=NA, "Estimate"="NOT ENOUGH DETECTIONS", "SE"=NA, "95% lower C.I."=NA, "95% upper C.I."=NA)',
                               '    colnames(WR.surv1) <- c("Measure", "Estimate", "SE", "95% lower C.I.", "95% upper C.I.")',
                               paste0('    print(kable(WR.surv1, row.names = F, "html", caption = "3.', table_count, ' Minimum through-Delta survival: City of Sacramento to Benicia (using CJS survival model)") %>%'),
                               '            kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
                               '',
                               '  } else {',
                               '    inp <- as.data.frame(reshape2::dcast(test4, TagCode ~ general_location, fun.aggregate = length))',
                               '',
                               '    # add together detections at Tower and I80 to ensure good detection entering Delta',
                               '    if("I80-50_Br" %in% colnames(inp) & "TowerBridge" %in% colnames(inp)){',
                               '      inp$`I80-50_Br` <- inp$`I80-50_Br` + inp$TowerBridge',
                               '',
                               '    } else if("TowerBridge" %in% colnames(inp)){',
                               '      inp$`I80-50_Br` <- inp$TowerBridge',
                               '    }',
                               '',
                               '    # Sort columns by river km in descending order, this also removes TowerBridge, no longer needed',
                               '    inp <- inp[,c("TagCode","I80-50_Br", "Benicia_east", "Benicia_west")]',
                               '',
                               '    # Count number of genlocs',
                               '    gen_loc_sites <- ncol(inp)-1',
                               '',
                               '    inp <- inp[,c(1,order(names(inp[,2:(gen_loc_sites+1)]), decreasing = T)+1)]',
                               '    inp <- merge(study_tagcodes, inp, by = "TagCode", all.x = T)',
                               '',
                               '    inp2 <- inp[,(ncol(inp)-gen_loc_sites+1):ncol(inp)]',
                               '    inp2[is.na(inp2)] <- 0',
                               '    inp2[inp2 > 0] <- 1',
                               '',
                               '    inp <- cbind(inp, inp2)',
                               '    groups <- as.character(sort(unique(inp$Release)))',
                               '    groups_w_detects <- names(table(detects_study[which(detects_study$river_km < 53),"Release"]))',
                               '    inp[,groups] <- 0',
                               '',
                               '    for(i in groups){',
                               '      inp[as.character(inp$Release) == i, i] <- 1',
                               '    }',
                               '',
                               '    inp$inp_final <- paste("1",apply(inp2, 1, paste, collapse=""),sep="")',
                               '',
                               '    if(length(groups) > 1){',
                               '      # make sure factor levels have a release that has detections first. if first release in factor order has zero #detectins, model goes haywire',
                               '      inp.df <- data.frame(ch = as.character(inp$inp_final), freq = 1, rel = inp$Release, stringsAsFactors = F)',
                               '',
                               '      WR.process <- process.data(inp.df, model="CJS", begin.time=1) ',
                               '',
                               '      WR.ddl <- make.design.data(WR.process)',
                               '',
                               '      WR.mark.all <- mark(WR.process, WR.ddl, model.parameters=list(Phi=list(formula=~time),p=list(formula=~time)),',
                               '                          silent = T, output = F)',
                               '',
                               '      inp.df <- inp.df[inp.df$rel %in% groups_w_detects,]',
                               '      inp.df$rel <- factor(inp.df$rel, levels = groups_w_detects)',
                               '',
                               '      if(length(groups_w_detects) > 1){',
                               '        WR.process <- process.data(inp.df, model="CJS", begin.time=1, groups = "rel")',
                               '',
                               '        WR.ddl <- make.design.data(WR.process)',
                               '',
                               '        WR.mark.rel <- mark(WR.process, WR.ddl, model.parameters=list(Phi=list(formula=~time*rel),p=list(formula=~time)),',
                               '                            silent = T, output = F)',
                               '',
                               '    } else {',
                               '      WR.process <- process.data(inp.df, model="CJS", begin.time=1) ',
                               '',
                               '      WR.ddl <- make.design.data(WR.process)',
                               '',
                               '      WR.mark.rel <- mark(WR.process, WR.ddl, model.parameters=list(Phi=list(formula=~time),p=list(formula=~time)),',
                               '                          silent = T, output = F)',
                               '    }',
                               '',
                               '    WR.surv <- cbind(Release = "ALL",round(WR.mark.all$results$real[2,c("estimate", "se", "lcl", "ucl")] * 100,1))',
                               '    WR.surv.rel <- cbind(Release = groups_w_detects,',
                               '                         round(WR.mark.rel$results$real[seq(from=2,to=length(groups_w_detects)*3,by = 3),',
                               '                                                        c("estimate", "se", "lcl", "ucl")] * 100,1))',
                               '    WR.surv.rel <- merge(WR.surv.rel, data.frame(Release = groups), all.y = T)',
                               '    WR.surv.rel[is.na(WR.surv.rel$estimate),"estimate"] <- 0',
                               '    WR.surv <- rbind(WR.surv, WR.surv.rel)',
                               '',
                               '    } else {',
                               '      inp.df <- data.frame(ch = as.character(inp$inp_final), freq = 1, stringsAsFactors = F)',
                               '',
                               '      WR.process <- process.data(inp.df, model="CJS", begin.time=1) ',
                               '',
                               '      WR.ddl <- make.design.data(WR.process)',
                               '',
                               '      WR.mark.all <- mark(WR.process, WR.ddl, model.parameters=list(Phi=list(formula=~time),p=list(formula=~time)),',
                               '                          silent = T, output = F)',
                               '      WR.surv <- cbind(Release = c("ALL", groups),round(WR.mark.all$results$real[2,c("estimate", "se", "lcl", "ucl")] * 100,1))',
                               '    }',
                               '',
                               '    WR.surv1 <- WR.surv',
                               '    colnames(WR.surv1) <- c("Release Group", "Survival (%)", "SE", "95% lower C.I.", "95% upper C.I.")',
                               paste0('    print(kable(WR.surv1, row.names = F, "html", caption = "3.', table_count, ' Minimum through-Delta survival: City of Sacramento to Benicia (using CJS survival model)") %>%'),
                               '              kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
                               '',
                               '    if(exists("Delta")==T & is.numeric(WR.surv1[1,2])){',
                               '      reltimes <- aggregate(list(RelDT = study_tagcodes$release_time), by = list(Release = study_tagcodes$Release), FUN = mean)',
                               '      reltimes <- rbind(reltimes, data.frame(Release = "ALL", RelDT = mean(study_tagcodes$release_time)))',
                               '',
                               '      # Assign whether the results are tentative or final',
                               '      quality <- "tentative"',
                               '      if(endtime < as.Date(format(Sys.time(), "%Y-%m-%d"))){',
                               '        quality <- "final"}',
                               '',
                               '      WR.surv <- merge(WR.surv, reltimes, by = "Release", all.x = T)',
                               '',
                               '      WR.surv$RelDT <- as.POSIXct(WR.surv$RelDT, origin = "1970-01-01")',
                               '',
                               '      Delta$RelDT <- as.POSIXct(Delta$RelDT)',
                               '',
                               '      # remove old benicia record for this studyID',
                               '      Delta <- Delta[!Delta$StudyID %in% unique(detects_study$Study_ID),]',
                               '      Delta <- rbind(Delta, data.frame(WR.surv, StudyID = unique(detects_study$Study_ID), data_quality = quality))',
                               '',
                               '      write.csv(Delta, "Delta_surv.csv", row.names = F, quote = F) ',
                               '    }',
                               '  }',
                               '}',
                               '```',
                               '',
                               '<br/>',
                               '',
                               sep = '\n')
      
      surv_tables <- paste(surv_tables,
                           surv_tables_tmp,
                           sep = "\n")
   }
   
   # Benicia
   if(release_region >= 1 & release_region <= 5){
      table_count <- table_count + 1
      
      surv_tables_tmp <- paste('```{r print table of survival to Benicia, message = FALSE, results= "asis", warning=FALSE}',
                               '',
                               paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
                               '',
                               'try(benicia <- read.csv("benicia_surv.csv", stringsAsFactors = F))',
                               '',
                               'detects_benicia <- detects_study[detects_study$general_location %in% c("Benicia_west", "Benicia_east"),]',
                               'endtime         <- min(as.Date(format(Sys.time(), "%Y-%m-%d")), max(as.Date(detects_study$release_time)+(as.numeric(detects_study$tag_life)*1.5)))',
                               '',
                               'if(nrow(detects_benicia) == 0){',
                               '  if(as.numeric(difftime(Sys.time(), min(detects_study$RelDT), units = "days"))>30){',
                               '    WR.surv <- data.frame("Release"="ALL", "estimate"=0, "se"=NA, "lcl"=NA, "ucl"=NA, "Detection_efficiency"=NA)',
                               '',
                               '  } else {',
                               '    WR.surv <- data.frame("Release"=NA, "estimate"="NO DETECTIONS YET", "se"=NA, "lcl"=NA, "ucl"=NA, "Detection_efficiency"=NA)',
                               '  }',
                               '',
                               '  WR.surv1 <- WR.surv',
                               '  colnames(WR.surv1) <- c("Release Group", "Survival (%)", "SE", "95% lower C.I.", "95% upper C.I.", "Detection efficiency (%)")',
                               paste0('  print(kable(WR.surv1, row.names = F, "html", caption = "3.', table_count, ' Minimum survival to Benicia Bridge East Span (using CJS survival model)") %>%'),
                               '          kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
                               '',
                               '} else if(length(table(detects_benicia$general_location)) == 1){',
                               '  if(as.numeric(difftime(Sys.time(), min(detects_study$RelDT), units = "days"))>30){',
                               '    WR.surv <- data.frame("Release"="ALL", "estimate"=round(length(unique(detects_benicia$TagCode))/length(unique(detects_study$TagCode))*100,1),',
                               '                          "se"=NA, "lcl"=NA, "ucl"=NA, "Detection_efficiency"=NA)',
                               '',
                               '  } else {',
                               '    WR.surv <- data.frame("Release" = NA, "estimate" = "NOT ENOUGH DETECTIONS", "se" = NA, "lcl" = NA, "ucl" = NA, "Detection_efficiency" = NA)',
                               '  }',
                               '',
                               '  WR.surv1 <- WR.surv',
                               '  colnames(WR.surv1) <- c("Release Group", "Survival (%)", "SE", "95% lower C.I.", "95% upper C.I.", "Detection efficiency (%)")',
                               paste0('  print(kable(WR.surv1, row.names = F, "html", caption = "3.', table_count, ' Minimum survival to Benicia Bridge East Span (using CJS survival model)") %>%'),
                               '         kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
                               '',
                               '} else {',
                               '  # Only do survival to Benicia here',
                               '  test3 <- detects_study[which(detects_study$river_km < 53),]',
                               '',
                               '  # Create inp for survival estimation',
                               '  inp <- as.data.frame(reshape2::dcast(test3, TagCode ~ river_km, fun.aggregate = length))',
                               '',
                               '  # Sort columns by river km in descending order',
                               '  # Count number of genlocs',
                               '  gen_loc_sites <- ncol(inp)-1',
                               '',
                               '  inp  <- inp[,c(1,order(names(inp[,2:(gen_loc_sites+1)]), decreasing = T)+1)]',
                               '  inp  <- merge(study_tagcodes, inp, by = "TagCode", all.x = T)',
                               '  inp2 <- inp[,(ncol(inp)-gen_loc_sites+1):ncol(inp)]',
                               '',
                               '  inp2[is.na(inp2)] <- 0',
                               '  inp2[inp2 > 0]    <- 1',
                               '',
                               '  inp    <- cbind(inp, inp2)',
                               '  groups <- as.character(sort(unique(inp$Release)))',
                               '  groups_w_detects <- names(table(test3$Release))',
                               '',
                               '  inp[,groups] <- 0',
                               '',
                               '  for(i in groups){',
                               '    inp[as.character(inp$Release) == i, i] <- 1',
                               '  }',
                               '',
                               '  inp$inp_final <- paste("1",apply(inp2, 1, paste, collapse=""),sep="")',
                               '',
                               '  if(length(groups) > 1){',
                               '      # make sure factor levels have a release that has detections first. if first release in factor order has zero #detectins, model goes haywire',
                               '       inp.df <- data.frame(ch = as.character(inp$inp_final), freq = 1, rel = inp$Release, stringsAsFactors = F)',
                               '',
                               '      WR.process <- process.data(inp.df, model="CJS", begin.time=1)',
                               '',
                               '      WR.ddl <- make.design.data(WR.process)',
                               '',
                               '      WR.mark.all <- mark(WR.process, WR.ddl, model.parameters=list(Phi=list(formula=~time),p=list(formula=~time)), silent = T, output = F)',
                               '',
                               '      inp.df <- inp.df[inp.df$rel %in% groups_w_detects,]',
                               '      inp.df$rel <- factor(inp.df$rel, levels = groups_w_detects)',
                               '',
                               '      if(length(groups_w_detects) > 1){',
                               '          WR.process <- process.data(inp.df, model="CJS", begin.time=1, groups = "rel")',
                               '          WR.ddl <- make.design.data(WR.process)',
                               '          WR.mark.rel <- mark(WR.process, WR.ddl, model.parameters=list(Phi=list(formula=~time*rel),p=list(formula=~time)), silent = T, output = F)',
                               '',
                               '      } else {',
                               '          WR.process <- process.data(inp.df, model="CJS", begin.time=1)',
                               '          WR.ddl <- make.design.data(WR.process)',
                               '          WR.mark.rel <- mark(WR.process, WR.ddl, model.parameters=list(Phi=list(formula=~time),p=list(formula=~time)), silent = T, output = F)',
                               '      }',
                               '',
                               '      WR.surv <- cbind(Release = "ALL",round(WR.mark.all$results$real[1,c("estimate", "se", "lcl", "ucl")] * 100,1))',
                               '      WR.surv.rel <- cbind(Release = groups_w_detects, round(WR.mark.rel$results$real[seq(from=1,to=length(groups_w_detects)*2,by = 2),',
                               '                                                                                  c("estimate", "se", "lcl", "ucl")] * 100,1))',
                               '      WR.surv.rel <- merge(WR.surv.rel, data.frame(Release = groups), all.y = T)',
                               '      WR.surv.rel[is.na(WR.surv.rel$estimate),"estimate"] <- 0',
                               '      WR.surv <- rbind(WR.surv, WR.surv.rel)',
                               '',
                               '  } else {',
                               '    inp.df      <- data.frame(ch = as.character(inp$inp_final), freq = 1, stringsAsFactors = F)',
                               '    WR.process  <- process.data(inp.df, model="CJS", begin.time=1) ',
                               '    WR.ddl      <- make.design.data(WR.process)',
                               '    WR.mark.all <- mark(WR.process, WR.ddl, model.parameters=list(Phi=list(formula=~time),p=list(formula=~time)), silent = T, output = F)',
                               '    WR.surv     <- cbind(Release = c("ALL", groups),round(WR.mark.all$results$real[1,c("estimate", "se", "lcl", "ucl")] * 100,1))',
                               '  }',
                               '',
                               '  WR.surv$Detection_efficiency <- NA',
                               '  WR.surv[1,"Detection_efficiency"] <- round(WR.mark.all$results$real[gen_loc_sites+1,"estimate"] * 100,1)',
                               '  WR.surv1 <- WR.surv',
                               '  colnames(WR.surv1) <- c("Release Group", "Survival (%)", "SE", "95% lower C.I.", "95% upper C.I.", "Detection efficiency (%)")',
                               '',
                               paste0('  print(kable(WR.surv1, row.names = F, "html", caption = "3.', table_count, ' Minimum survival to Benicia Bridge East Span (using CJS survival model)") %>%'),
                               '          kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
                               '}',
                               '',
                               'if(exists("benicia")==T & is.numeric(WR.surv1[1,2])){',
                               '  # Find mean release time per release group, and ALL',
                               '  reltimes <- aggregate(list(RelDT = study_tagcodes$release_time), by = list(Release = study_tagcodes$Release), FUN = mean)',
                               '  reltimes <- rbind(reltimes, data.frame(Release = "ALL", RelDT = mean(study_tagcodes$release_time)))',
                               '',
                               '  # Assign whether the results are tentative or final',
                               '  quality <- "tentative"',
                               '  if(endtime < as.Date(format(Sys.time(), "%Y-%m-%d"))){', 
                               '    quality <- "final"',
                               '}',
                               '',
                               '  WR.surv       <- merge(WR.surv, reltimes, by = "Release", all.x = T)',
                               '  WR.surv$RelDT <- as.POSIXct(WR.surv$RelDT, origin = "1970-01-01")',
                               '  benicia$RelDT <- as.POSIXct(benicia$RelDT)',
                               '',
                               '  # remove old benicia record for this studyID',
                               '  benicia <- benicia[!benicia$StudyID == unique(detects_study$Study_ID),]',
                               '  benicia <- rbind(benicia, data.frame(WR.surv, StudyID = unique(detects_study$Study_ID), data_quality = quality))',
                               '',
                               '  write.csv(benicia, "benicia_surv.csv", row.names = F, quote = F) ',
                               '}',
                               '```',
                               '',
                               '<br/>',
                               '',
                               sep = '\n')
      
      surv_tables <- paste(surv_tables,
                           surv_tables_tmp,
                           sep = "\n")
   }
   
   return(surv_tables)
}

# Create detection statistics
create_detection_stats <- function(){
   detect_stats <- paste('***',
                         '## _4. Detections statistics at all realtime receivers_',
                         '***',
                         '',
                         sep = '\n')
   
   table_count <- 1
   
   detect_stats <- paste(detect_stats,
                         '```{r print tables of fish detections, message = FALSE, results= "asis", warning=FALSE}',
                         '',
                         paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
                         '',
                         'if(nrow(detects_study[is.na(detects_study$DateTime_PST)==F,]) == 0){',
                         '  "No detections yet"',
                         '',
                         '} else {',
                         '  arrivals <- detects_study %>%',
                         '              group_by(general_location, TagCode) %>%',
                         '              summarise(DateTime_PST = min(DateTime_PST)) %>%',
                         '              arrange(TagCode)',
                         '',
                         '  tag_stats <- arrivals %>%',
                         '               group_by(general_location) %>%',
                         '               summarise(First_arrival = min(DateTime_PST),',
                         '                         Mean_arrival = mean(DateTime_PST),',
                         '                         Last_arrival = max(DateTime_PST),',
                         '                         Fish_count = length(unique(TagCode))) %>%',
                         '               mutate(Percent_arrived = round(Fish_count/nrow(study_tagcodes) * 100,2)) %>%',
                         '               dplyr::left_join(., unique(detects_study[,c("general_location", "river_km")])) %>%',
                         '               arrange(desc(river_km)) %>%',
                         '               mutate(First_arrival = format(First_arrival, tz = "Etc/GMT+8"),',
                         '                      Mean_arrival = format(Mean_arrival, tz = "Etc/GMT+8"),',
                         '                      Last_arrival = format(Last_arrival, tz = "Etc/GMT+8")) %>%',
                         '               na.omit()',
                         '',
                         '  print(kable(tag_stats, row.names = F,',
                         paste0('              caption = "4.', table_count, ' Detections for all releases combined",'),
                         '              "html") %>%',
                         '          kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
                         '',
                         '  count <- 0',
                         '',
                         '  for(j in sort(unique(study_tagcodes$Release))){',
                         '',
                         '    if(nrow(detects_study[detects_study$Release == j,]) > 0){',
                         '      count <- count + 1',
                         '      arrivals1 <- detects_study %>%',
                         '                   filter(Release == j) %>%',
                         '                   group_by(general_location, TagCode) %>%',
                         '                   summarise(DateTime_PST = min(DateTime_PST)) %>%',
                         '                   arrange(TagCode)',
                         '',
                         '      rel_count <- nrow(study_tagcodes[study_tagcodes$Release == j,])',
                         '',
                         '      tag_stats1 <- arrivals1 %>%',
                         '                    group_by(general_location) %>%',
                         '                    summarise(First_arrival = min(DateTime_PST),',
                         '                              Mean_arrival = mean(DateTime_PST),',
                         '                              Last_arrival = max(DateTime_PST),',
                         '                              Fish_count = length(unique(TagCode))) %>%',
                         '                    mutate(Percent_arrived = round(Fish_count/rel_count * 100,2)) %>%',
                         '                    dplyr::left_join(., unique(detects_study[,c("general_location", "river_km")])) %>%',
                         '                    arrange(desc(river_km)) %>%',
                         '                    mutate(First_arrival = format(First_arrival, tz = "Etc/GMT+8"),',
                         '                           Mean_arrival = format(Mean_arrival, tz = "Etc/GMT+8"),',
                         '                           Last_arrival = format(Last_arrival, tz = "Etc/GMT+8")) %>%',
                         '                    na.omit()',
                         '',
                         '      final_stats <- kable(tag_stats1, row.names = F,',
                         paste0('            caption = paste("4.', table_count + 1, '.", count, " Detections for ", j, " release groups", sep = ""),'),
                         '            "html")',
                         '      print(kable_styling(final_stats, bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), full_width = F, position = "left"))',
                         '',
                         '    } else {',
                         paste0('      cat("', '\\', 'n', '\\', 'n', '\\', '\\', 'pagebreak', '\\', 'n")'),
                         '      print(paste("No detections for",j,"release group yet", sep=" "), quote = F)',
                         
                         paste0('      cat("', '\\', 'n', '\\', 'n', '\\', '\\', 'pagebreak', '\\', 'n")'),
                         '    }',
                         '  }',
                         '}',
                         '```',
                         '',
                         '<br/>',
                         '',
                         sep = '\n')
   
   table_count <- table_count + 2
   
   detect_stats <- paste(detect_stats,
                         '```{r print tables of fish detections per day, message = FALSE, results= "asis", warning=FALSE}',
                         '',
                         paste0('try(setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep=', '"', '\\', '\\', '"), "', '\\', '\\', 'Real-time data massaging', '\\', '\\', 'products", sep = "")))'),
                         '',
                         '# THIS CODE CHUNK WILL NOT WORK IF USING ONLY ERDDAP DATA, REQUIRES ACCESS TO LOCAL FILES',
                         'if(nrow(detects_study[is.na(detects_study$DateTime_PST)==F,]) == 0){',
                         '  "No detections yet"',
                         '',
                         '} else {',
                         '  arrivals <- detects_study %>%',
                         '              group_by(general_location, TagCode) %>%',
                         '              summarise(DateTime_PST = min(DateTime_PST)) %>%',
                         '              mutate(day = as.Date(format(DateTime_PST, "%Y-%m-%d", tz = "Etc/GMT+8")))',
                         '',
                         '  gen_locs <- read.csv("realtime_locs.csv", stringsAsFactors = F)',
                         '',
                         '  beacon_by_day <- fread("beacon_by_day.csv", stringsAsFactors = F) %>%',
                         '                   mutate(day = as.Date(day)) %>%',
                         '                   filter(TagCode == beacon) %>% # Now subset to only look at data for the correct beacon for that day',
                         '                   filter(day >= as.Date(min(study_tagcodes$release_time)) & ',
                         '                          day <= endtime) %>% # Now only keep beacon by day for days since fish were released',
                         '                   dplyr::left_join(., gen_locs[,c("location", "general_location","rkm")], by = "location")',
                         '',
                         '  arrivals_per_day <- arrivals %>%',
                         '                      group_by(day, general_location) %>%',
                         '                      summarise(New_arrivals = length(TagCode)) %>%',
                         '                      arrange(general_location) %>% na.omit() %>%',
                         '                      mutate(day = as.Date(day)) %>%',
                         '                      dplyr::left_join(unique(beacon_by_day[,c("general_location", "day", "rkm")]),',
                         '                                       ., by = c("general_location", "day")) %>%',
                         '                      arrange(general_location, day) %>%',
                         '                      mutate(day = factor(day)) %>%',
                         '                      filter(general_location != "Bench_test") %>% # Remove bench test and other NA locations',
                         '                      filter(!(is.na(general_location))) %>%',
                         '                      arrange(desc(rkm)) %>% # Change order of data to plot decreasing river_km',
                         '                      mutate(general_location = factor(general_location, unique(general_location)))',
                         '',
                         '  endtime <- min(as.Date(format(Sys.time(), "%Y-%m-%d")),',
                         '                 max(as.Date(detects_study$release_time)+(as.numeric(detects_study$tag_life)*1.5)))',
                         '',
                         '  crosstab <- xtabs(formula = arrivals_per_day$New_arrivals ~ arrivals_per_day$day + arrivals_per_day$general_location,',
                         '                    addNA =T)',
                         '  crosstab[is.na(crosstab)] <- ""',
                         '  crosstab[crosstab==0] <- NA',
                         '  crosstab <- as.data.frame.matrix(crosstab)',
                         '',
                         paste0('  kable(crosstab, align = "c", caption = "4.3 Fish arrivals per day (', "\\", '"NA', "\\", '" means receivers were non-operational)") %>%'),
                         '    kable_styling(c("striped", "condensed"), font_size = 11, full_width = F, position = "left", fixed_thead = TRUE) %>%',
                         '    column_spec(column = 1:ncol(crosstab),width_min = "50px",border_left = T, border_right = T) %>%',
                         '    column_spec(1, bold = T, width_min = "75px")%>%',
                         '    scroll_box(height = "700px")',
                         '}',
                         '',
                         'rm(list = ls())',
                         'cleanup(ask = F)',
                         '```',
                         '',
                         '<br/>',
                         '<br/>',
                         '',
                         '***For questions or comments, please contact cyril.michel@noaa.gov***',
                         sep = "\n")
   
   return(detect_stats)
}
